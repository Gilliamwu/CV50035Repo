{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#/usr/bin/python2\n",
    "# coding: utf-8\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import codecs\n",
    "import re\n",
    "import sugartensor as tf\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print' (<ipython-input-2-b371b905ee5b>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-b371b905ee5b>\"\u001b[1;36m, line \u001b[1;32m9\u001b[0m\n\u001b[1;33m    print \"# Make classes\"\u001b[0m\n\u001b[1;37m                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m Missing parentheses in call to 'print'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# image file path\n",
    "class Hyperparams:\n",
    "    image_fpath = '../../datasets/Kylberg Texture Dataset v. 1.0/without-rotations-zip/*/*.png'\n",
    "\n",
    "class Data:\n",
    "    def __init__(self, batch_size=16):\n",
    "        \n",
    "        print \"# Make classes\"\n",
    "        import glob\n",
    "        files = glob.glob(Hyperparams.image_fpath)\n",
    "        labels = [f.split('/')[-1].split('-')[0] for f in files] # ['scarf2', 'scarf1', ...]\n",
    "\n",
    "        self.idx2label = {idx:label for idx, label in enumerate(set(labels))}\n",
    "        self.label2idx = {label:idx for idx, label in self.idx2label.items()}    \n",
    "        \n",
    "        labels = [self.label2idx[label] for label in labels] # [3, 4, 6, ...]\n",
    "        \n",
    "        files = tf.convert_to_tensor(files) #(4480,) (4480,)\n",
    "        labels = tf.convert_to_tensor(labels) #(4480,) (4480,)\n",
    "        \n",
    "        file_q, label_q = tf.train.slice_input_producer([files, labels], num_epochs=1) #  (), ()\n",
    "        img_q = tf.image.decode_png(tf.read_file(file_q), channels=1) # (576, 576, 1) uint8\n",
    "        img_q = self.transform_image(img_q) # (224, 224, 1) float32\n",
    "        \n",
    "        self.x, self.y = tf.train.shuffle_batch([img_q, label_q], batch_size,\n",
    "                                             num_threads=32, capacity=batch_size*128,\n",
    "                                             min_after_dequeue=batch_size*32, \n",
    "                                             allow_smaller_final_batch=False)      # (16, 224, 224, 1) (16,)   \n",
    "\n",
    "    def transform_image(self, img):\n",
    "        r\"\"\"\n",
    "        Arg:\n",
    "          img: A 3-D tensor.\n",
    "          \n",
    "        Returns:\n",
    "          A `Tensor`. Has the shape of (224, 224) and dtype of float32.\n",
    "        \"\"\"\n",
    "        # center crop\n",
    "        offset_height = (576-224)/2\n",
    "        offset_width = offset_height\n",
    "        img = tf.image.crop_to_bounding_box(img, offset_height, offset_width, 224, 224)\n",
    "        # normalization\n",
    "        img = img.sg_float() / 255\n",
    "    \n",
    "        return img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m--------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-3038fcb5bcaa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtrain\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModelGraph\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'train'"
     ]
    }
   ],
   "source": [
    "\n",
    "from train import ModelGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV_env",
   "language": "python",
   "name": "virtualenvcv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
