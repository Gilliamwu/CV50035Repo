{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/tutorials/layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import sys\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import pylab as pl\n",
    "import math\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import helper.get_image as gi\n",
    "from filters import GrayscaleNormalizer\n",
    "\n",
    "# This is a bit of magic to make matplotlib figures appear inline in the notebook\n",
    "# rather than in a new window.\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "# automatically reload imported modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 227, 227) (4000,)\n",
      "(80, 227, 227) (80,)\n",
      "(200, 227, 227) (200,)\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "FOLDER_PATH = '..'\n",
    "# random\n",
    "train_size = 2000\n",
    "test_size = 100\n",
    "val_size = 40\n",
    "\n",
    "# img_range = np.arange(1, 20001)\n",
    "# X_train_pos_idx, X_test_pos_idx, X_val_pos_idx = gi.get_random_indices(img_range, train_size, test_size, val_size)\n",
    "# X_train_neg_idx, X_test_neg_idx, X_val_neg_idx = gi.get_random_indices(img_range, train_size, test_size, val_size)\n",
    "\n",
    "# X_train, Y_train = gi.get_concrete_data(X_train_pos_idx, X_train_neg_idx, path = FOLDER_PATH)\n",
    "# X_test , Y_test  = gi.get_concrete_data(X_test_pos_idx, X_test_neg_idx, path = FOLDER_PATH)\n",
    "# X_val  , Y_val   = gi.get_concrete_data(X_val_pos_idx, X_val_neg_idx, path = FOLDER_PATH)\n",
    "\n",
    "# print( X_train.shape, Y_train.shape )\n",
    "# print( X_test.shape , Y_test.shape  )\n",
    "# print( X_val.shape  , Y_val.shape   )\n",
    "#fixed from range\n",
    "X_train, Y_train = gi.get_concrete_data(range(1601, 3601), range(1601, 3601), path = FOLDER_PATH)\n",
    "X_test , Y_test  = gi.get_concrete_data(range(501 , 541 ), range(501 , 541 ), path = FOLDER_PATH)\n",
    "X_val  , Y_val   = gi.get_concrete_data(range(1001, 1101), range(1001, 1101), path = FOLDER_PATH)\n",
    "\n",
    "print( X_train.shape, Y_train.shape )\n",
    "print( X_test.shape , Y_test.shape  )\n",
    "print( X_val.shape  , Y_val.shape   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTPTNRate(l,p):#label, predictions\n",
    "    tn, fp, fn, tp = confusion_matrix(l, p).ravel()\n",
    "    tpr = float(tp)/(float(tp) + float(fn))\n",
    "    tnr=float(tn)/(float(tn) + float(fp))\n",
    "    return tpr,tnr\n",
    "# this is for training \n",
    "def run_model_TF(session, predict, loss_val, Xd, yd,\n",
    "              epochs=1, batch_size=64, print_every=100,\n",
    "              training=None, plot_losses=False):\n",
    "    \n",
    "    # have tensorflow compute accuracy\n",
    "    predictions=tf.argmax(predict,1)\n",
    "    correct_prediction = tf.equal(predictions, y)#array of true and false\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    \n",
    "    actuals=y\n",
    "    ones_like_actuals = tf.ones_like(actuals)#all elements set to 1\n",
    "    zeros_like_actuals = tf.zeros_like(actuals) #all elements set to 0\n",
    "    ones_like_predictions = tf.ones_like(predictions) #all elements set to 1\n",
    "    zeros_like_predictions = tf.zeros_like(predictions) #all elements set to 0\n",
    "    \n",
    "    tp_op = tf.count_nonzero(predictions * actuals)\n",
    "    tn_op = tf.count_nonzero((predictions - 1) * (actuals - 1))\n",
    "    fp_op = tf.count_nonzero(predictions * (actuals - 1))\n",
    "    fn_op = tf.count_nonzero((predictions - 1) * actuals)\n",
    " \n",
    "    train_indicies = np.arange(Xd.shape[0])\n",
    "    \n",
    "    training_now = (training is not None)\n",
    "    \n",
    "    # setting up variables we want to compute (and optimizing)\n",
    "    # if we have a training function, add that to things we compute\n",
    "    variables = [mean_loss, tp_op, tn_op, fp_op, fn_op, correct_prediction,accuracy]\n",
    "    if training_now:\n",
    "        variables[-1] = training\n",
    "\n",
    "    # counter \n",
    "    iter_cnt = 0\n",
    "    # keep track of losses\n",
    "    losses = []\n",
    "\n",
    "\n",
    "    for e in range(epochs):\n",
    "        # shuffle indicies\n",
    "        np.random.shuffle(train_indicies)\n",
    "        total_tp=0\n",
    "        total_tn=0\n",
    "        total_fp=0\n",
    "        total_fn=0\n",
    "        correct = 0\n",
    "\n",
    "        # make sure we iterate over the dataset once\n",
    "        for i in range(int(math.ceil(Xd.shape[0]/batch_size))):\n",
    "            # generate indicies for the batch\n",
    "            start_idx = (i*batch_size)%Xd.shape[0]\n",
    "            idx = train_indicies[start_idx:start_idx+batch_size]\n",
    "            \n",
    "            # create a feed dictionary for this batch\n",
    "            feed_dict = {X: Xd[idx,:],\n",
    "                         y: yd[idx],\n",
    "                         is_training: training_now }\n",
    "            # get batch size\n",
    "            actual_batch_size = yd[idx].shape[0]\n",
    "            \n",
    "            # have tensorflow compute loss and correct predictions\n",
    "            # and (if given) perform a training step\n",
    "            loss, tp, tn, fp, fn, corr,_= session.run(variables,feed_dict=feed_dict) #last variable will be automatically be None \n",
    "\n",
    "\n",
    "            print(tp,tn,fp,fn)\n",
    "            total_tp+=tp\n",
    "            total_tn+=tn\n",
    "            total_fp+=fp \n",
    "            total_fn+=fn\n",
    "            tpr = float(tp)/(float(tp) + float(fn))\n",
    "#             fpr = float(fp)/(float(tp) + float(fn))\n",
    "            tnr=float(tn)/(float(tn) + float(fp))\n",
    "#             accuracy = (float(tp) + float(tn))/(float(tp) + float(fp) + float(fn) + float(tn))\n",
    "            \n",
    "#             recall = tpr\n",
    "#             precision = float(tp)/(float(tp) + float(fp))\n",
    "#             f1_score = (2.0 * (precision * recall)) / (precision + recall)\n",
    "            \n",
    "            # aggregate performance stats\n",
    "            losses.append(loss*actual_batch_size)\n",
    "\n",
    "            corr = np.array(corr).astype(np.float32)\n",
    "            \n",
    "            correct += np.sum(corr)\n",
    "\n",
    "            \n",
    "            # print every now and then\n",
    "            if training_now and (iter_cnt % print_every) == 0:\n",
    "                print(\"Iteration {0}: with minibatch training loss = {1:.3g},tpr of {2:.2g},tnr of {3:.2g} and accuracy of {4:.2g}\"\\\n",
    "                      .format(iter_cnt,loss,tpr,tnr,np.sum(corr)/actual_batch_size))\n",
    "            iter_cnt += 1\n",
    "        total_tpr = total_tp/(total_tp+total_fn)\n",
    "        total_tnr=total_tn/(total_tn+total_fp)\n",
    "        total_loss = np.sum(losses)/Xd.shape[0]\n",
    "        total_correct = correct/Xd.shape[0]\n",
    "        \n",
    "\n",
    "\n",
    "        print(\"Epoch {0}, Overall loss = {1:.3g} tpr of {2:.3g},tnr of {3:.3g} and accuracy of {4:.3g}\"\\\n",
    "              .format(e+1,total_loss,total_tpr,total_tnr,total_correct))\n",
    "    \n",
    "        \n",
    "    if plot_losses:\n",
    "        plt.plot(losses)\n",
    "        plt.grid(True)\n",
    "        plt.title('Epoch {} Loss'.format(e+1))\n",
    "        plt.xlabel('minibatch number')\n",
    "        plt.ylabel('minibatch loss')\n",
    "        plt.show()\n",
    "            \n",
    "    return total_loss,total_tpr,total_tnr,losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "14 17 16 17\n",
      "Iteration 0: with minibatch training loss = 1.43,tpr of 0.45,tnr of 0.52 and accuracy of 0.48\n",
      "21 22 11 10\n",
      "29 24 1 10\n",
      "25 30 2 7\n",
      "26 30 1 7\n",
      "24 28 2 10\n",
      "24 29 3 8\n",
      "22 29 3 10\n",
      "21 30 3 10\n",
      "18 39 1 6\n",
      "25 24 5 10\n",
      "25 29 4 6\n",
      "23 31 4 6\n",
      "19 36 4 5\n",
      "23 32 3 6\n",
      "23 24 6 11\n",
      "23 32 0 9\n",
      "23 29 1 11\n",
      "26 28 1 9\n",
      "28 25 0 11\n",
      "28 24 6 6\n",
      "27 26 6 5\n",
      "22 30 8 4\n",
      "27 28 6 3\n",
      "27 28 1 8\n",
      "28 27 5 4\n",
      "28 31 2 3\n",
      "28 26 3 7\n",
      "18 35 3 8\n",
      "30 23 1 10\n",
      "29 27 1 7\n",
      "23 26 11 4\n",
      "28 28 1 7\n",
      "25 33 2 4\n",
      "24 34 0 6\n",
      "28 27 0 9\n",
      "27 28 1 8\n",
      "22 33 6 3\n",
      "28 28 3 5\n",
      "22 30 2 10\n",
      "33 27 0 4\n",
      "26 33 2 3\n",
      "24 34 4 2\n",
      "29 28 0 7\n",
      "27 28 3 6\n",
      "27 32 1 4\n",
      "25 29 1 9\n",
      "32 28 1 3\n",
      "31 27 1 5\n",
      "23 30 8 3\n",
      "29 29 0 6\n",
      "35 25 0 4\n",
      "25 35 3 1\n",
      "25 33 2 4\n",
      "32 26 0 6\n",
      "30 30 1 3\n",
      "31 31 0 2\n",
      "23 33 2 6\n",
      "23 30 8 3\n",
      "28 33 2 1\n",
      "30 26 2 6\n",
      "27 31 2 4\n",
      "12 18 2 0\n",
      "Epoch 1, Overall loss = 0.475 tpr of 0.804,tnr of 0.908 and accuracy of 0.856\n",
      "27 35 0 2\n",
      "28 29 0 7\n",
      "24 32 2 6\n",
      "25 35 2 2\n",
      "25 35 1 3\n",
      "23 35 1 5\n",
      "27 33 0 4\n",
      "24 35 2 3\n",
      "26 33 1 4\n",
      "28 33 1 2\n",
      "32 26 2 4\n",
      "29 31 0 4\n",
      "32 23 3 6\n",
      "28 33 0 3\n",
      "30 34 0 0\n",
      "27 34 1 2\n",
      "31 25 1 7\n",
      "28 32 2 2\n",
      "24 34 0 6\n",
      "27 33 0 4\n",
      "33 25 1 5\n",
      "29 30 0 5\n",
      "27 34 0 3\n",
      "26 34 2 2\n",
      "30 30 1 3\n",
      "34 26 0 4\n",
      "28 29 3 4\n",
      "27 31 2 4\n",
      "29 33 2 0\n",
      "32 25 0 7\n",
      "27 31 2 4\n",
      "28 33 0 3\n",
      "28 31 1 4\n",
      "26 33 4 1\n",
      "29 33 2 0\n",
      "25 35 2 2\n",
      "35 28 0 1\n",
      "24 34 3 3\n",
      "Iteration 100: with minibatch training loss = 0.217,tpr of 0.89,tnr of 0.92 and accuracy of 0.91\n",
      "31 30 0 3\n",
      "28 32 0 4\n",
      "31 29 2 2\n",
      "36 18 0 10\n",
      "31 30 2 1\n",
      "31 29 0 4\n",
      "31 31 0 2\n",
      "30 28 0 6\n",
      "31 33 0 0\n",
      "30 27 1 6\n",
      "31 28 0 5\n",
      "27 32 2 3\n",
      "31 29 2 2\n",
      "22 37 1 4\n",
      "22 36 5 1\n",
      "27 33 1 3\n",
      "30 31 0 3\n",
      "28 31 0 5\n",
      "28 30 1 5\n",
      "34 25 1 4\n",
      "27 30 2 5\n",
      "32 29 0 3\n",
      "29 32 1 2\n",
      "27 32 0 5\n",
      "13 18 0 1\n",
      "Epoch 2, Overall loss = 0.677 tpr of 0.89,tnr of 0.968 and accuracy of 0.929\n",
      "30 32 0 2\n",
      "33 29 1 1\n",
      "29 31 1 3\n",
      "30 31 1 2\n",
      "20 37 7 0\n",
      "36 25 0 3\n",
      "26 33 3 2\n",
      "34 30 0 0\n",
      "26 34 1 3\n",
      "25 37 1 1\n",
      "33 30 0 1\n",
      "31 31 0 2\n",
      "34 29 0 1\n",
      "34 27 0 3\n",
      "23 35 5 1\n",
      "24 36 3 1\n",
      "31 30 1 2\n",
      "31 30 1 2\n",
      "31 30 0 3\n",
      "25 34 4 1\n",
      "32 24 0 8\n",
      "28 32 4 0\n",
      "34 28 0 2\n",
      "35 26 0 3\n",
      "30 34 0 0\n",
      "33 30 0 1\n",
      "25 38 1 0\n",
      "32 31 0 1\n",
      "24 35 4 1\n",
      "31 31 1 1\n",
      "36 27 0 1\n",
      "30 32 1 1\n",
      "32 30 0 2\n",
      "23 39 1 1\n",
      "30 31 2 1\n",
      "31 29 1 3\n",
      "31 30 2 1\n",
      "36 25 0 3\n",
      "30 33 0 1\n",
      "32 28 3 1\n",
      "34 29 0 1\n",
      "33 31 0 0\n",
      "28 32 2 2\n",
      "30 32 0 2\n",
      "32 31 0 1\n",
      "27 30 6 1\n",
      "33 28 1 2\n",
      "27 35 1 1\n",
      "34 27 0 3\n",
      "33 30 0 1\n",
      "30 31 0 3\n",
      "31 31 0 2\n",
      "25 36 0 3\n",
      "28 35 1 0\n",
      "29 31 0 4\n",
      "29 33 1 1\n",
      "30 31 0 3\n",
      "31 30 1 2\n",
      "30 31 0 3\n",
      "33 30 0 1\n",
      "32 29 0 3\n",
      "37 23 0 4\n",
      "13 17 1 1\n",
      "Epoch 3, Overall loss = 0.809 tpr of 0.945,tnr of 0.969 and accuracy of 0.957\n",
      "33 29 1 1\n",
      "31 33 0 0\n",
      "30 32 1 1\n",
      "35 26 0 3\n",
      "31 32 1 0\n",
      "27 34 3 0\n",
      "27 36 0 1\n",
      "28 33 2 1\n",
      "33 31 0 0\n",
      "35 25 2 2\n",
      "27 34 2 1\n",
      "32 29 0 3\n",
      "Iteration 200: with minibatch training loss = 0.102,tpr of 0.91,tnr of 1 and accuracy of 0.95\n",
      "27 35 0 2\n",
      "24 37 2 1\n",
      "23 37 4 0\n",
      "29 35 0 0\n",
      "29 33 1 1\n",
      "26 36 2 0\n",
      "36 25 0 3\n",
      "29 35 0 0\n",
      "39 22 0 3\n",
      "33 30 0 1\n",
      "29 31 1 3\n",
      "31 32 0 1\n",
      "33 29 1 1\n",
      "30 33 0 1\n",
      "28 36 0 0\n",
      "29 35 0 0\n",
      "29 32 1 2\n",
      "33 28 0 3\n",
      "27 33 1 3\n",
      "28 35 0 1\n",
      "33 25 0 6\n",
      "34 29 0 1\n",
      "33 31 0 0\n",
      "27 34 1 2\n",
      "23 37 1 3\n",
      "32 28 0 4\n",
      "32 31 0 1\n",
      "35 25 1 3\n",
      "26 33 3 2\n",
      "25 35 3 1\n",
      "33 29 1 1\n",
      "32 31 1 0\n",
      "33 30 0 1\n",
      "33 30 1 0\n",
      "34 28 1 1\n",
      "35 28 0 1\n",
      "33 30 0 1\n",
      "34 28 0 2\n",
      "34 25 0 5\n",
      "31 33 0 0\n",
      "33 27 0 4\n",
      "24 36 2 2\n",
      "34 27 0 3\n",
      "31 31 0 2\n",
      "29 32 2 1\n",
      "30 33 0 1\n",
      "27 34 1 2\n",
      "29 34 0 1\n",
      "31 32 1 0\n",
      "32 28 0 4\n",
      "13 18 1 0\n",
      "Epoch 4, Overall loss = 0.909 tpr of 0.953,tnr of 0.978 and accuracy of 0.965\n",
      "29 35 0 0\n",
      "30 34 0 0\n",
      "28 35 0 1\n",
      "35 29 0 0\n",
      "30 34 0 0\n",
      "34 29 0 1\n",
      "33 30 0 1\n",
      "32 30 0 2\n",
      "29 33 1 1\n",
      "28 35 0 1\n",
      "29 35 0 0\n",
      "24 38 2 0\n",
      "30 32 0 2\n",
      "36 28 0 0\n",
      "32 28 0 4\n",
      "35 28 0 1\n",
      "32 31 0 1\n",
      "34 29 0 1\n",
      "28 36 0 0\n",
      "36 27 0 1\n",
      "35 29 0 0\n",
      "25 39 0 0\n",
      "31 32 0 1\n",
      "27 35 1 1\n",
      "33 31 0 0\n",
      "33 30 0 1\n",
      "33 30 0 1\n",
      "32 32 0 0\n",
      "35 29 0 0\n",
      "27 37 0 0\n",
      "31 31 1 1\n",
      "31 32 0 1\n",
      "31 33 0 0\n",
      "29 35 0 0\n",
      "30 32 0 2\n",
      "30 34 0 0\n",
      "33 31 0 0\n",
      "24 39 1 0\n",
      "28 35 0 1\n",
      "31 32 0 1\n",
      "22 42 0 0\n",
      "28 34 2 0\n",
      "28 35 1 0\n",
      "35 27 0 2\n",
      "28 36 0 0\n",
      "24 40 0 0\n",
      "33 30 0 1\n",
      "34 27 1 2\n",
      "37 25 0 2\n",
      "Iteration 300: with minibatch training loss = 0.0946,tpr of 0.95,tnr of 1 and accuracy of 0.97\n",
      "37 26 0 1\n",
      "38 25 0 1\n",
      "32 31 0 1\n",
      "37 26 0 1\n",
      "29 35 0 0\n",
      "34 30 0 0\n",
      "33 29 0 2\n",
      "33 28 2 1\n",
      "32 32 0 0\n",
      "31 33 0 0\n",
      "33 31 0 0\n",
      "36 27 0 1\n",
      "29 34 0 1\n",
      "20 11 0 1\n",
      "Epoch 5, Overall loss = 0.962 tpr of 0.978,tnr of 0.994 and accuracy of 0.986\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAAHwCAYAAADjOch3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nojwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116603940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'../trained_model/cnn_model'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CNN_model:\n",
    "    def __init__(self,X_train,Y_train):\n",
    "        self.X_train=X_train\n",
    "        self.Y_train=Y_train\n",
    "        \n",
    "    def cnn_model_fn(self,X, labels, is_training):\n",
    "        #1-layer model: conv-pool-fc-fc-softmax with batch normalization \n",
    "  # Input Layer\n",
    "  # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n",
    "        input_layer = tf.reshape(X, [-1, 227, 227, 1])\n",
    "\n",
    "        conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=8,\n",
    "      kernel_size=[3, 3],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "        bn1act = tf.layers.batch_normalization(inputs=conv1, training=is_training)\n",
    "\n",
    "        pool1 = tf.layers.max_pooling2d(inputs=bn1act, pool_size=[2, 2], strides=2)\n",
    "       \n",
    "  # Flatten tensor into a batch of vectors\n",
    "        pool1_flat = tf.reshape(pool1, [-1, 113 * 113 * 8])\n",
    "\n",
    "  # Dense Layer\n",
    "  # Densely connected layer with 128 neurons\n",
    "        dense = tf.layers.dense(inputs=pool1_flat, units=1024, activation=tf.nn.relu)\n",
    "        bn2act = tf.layers.batch_normalization(inputs=dense, training=is_training)\n",
    "\n",
    "  # Add dropout operation; 0.6 probability that element will be kept to avoid overfitting\n",
    "        dropout = tf.layers.dropout(\n",
    "      inputs=bn2act, rate=0.4, training=is_training)\n",
    "\n",
    "  # Logits layer\n",
    "  # Input Tensor Shape: [batch_size, 128]\n",
    "  # Output Tensor Shape: [batch_size, 2]\n",
    "        logits = tf.layers.dense(inputs=dropout, units=2,activation=None,name=\"logits\")\n",
    "        return logits\n",
    "\n",
    "\n",
    "#load model\n",
    "model=CNN_model(X_train,Y_train)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 227, 227],name=\"X\")\n",
    "y = tf.placeholder(tf.int64, [None],name=\"y\")\n",
    "is_training = tf.placeholder(tf.bool,name=\"training\")\n",
    "\n",
    "y_out = model.cnn_model_fn(X,y,is_training)\n",
    "# print(y_out)\n",
    "# print(is_training)\n",
    "total_loss = tf.losses.softmax_cross_entropy(logits=y_out, onehot_labels=tf.one_hot(y,2))\n",
    "mean_loss = tf.reduce_mean(total_loss)\n",
    "optimizer = tf.train.AdamOptimizer(1e-4) #adam\n",
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(extra_update_ops):\n",
    "    train_step = optimizer.minimize(mean_loss)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver()\n",
    "print('Training')\n",
    "run_model_TF(sess,y_out,mean_loss,X_train,Y_train,5,64,100,train_step,True)\n",
    "#save the model\n",
    "#the training is over 4000 data(2000 pos 2000 neg) over 5 epoch\n",
    "saver.save(sess, '../trained_model/cnn_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../trained_model/cnn_model\n",
      "Test\n",
      "[1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0]\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "true positive rate 0.975 true negative rate 0.975\n"
     ]
    }
   ],
   "source": [
    "#this is to load the saved trained model\n",
    "\n",
    "sess=tf.Session()    \n",
    "#retrieve the model\n",
    "saver = tf.train.import_meta_graph('../trained_model/cnn_model.meta')\n",
    "saver.restore(sess, '../trained_model/cnn_model')\n",
    "graph = tf.get_default_graph()\n",
    "stored_y_out = graph.get_tensor_by_name(\"logits/BiasAdd:0\")\n",
    "X = graph.get_tensor_by_name(\"X:0\")\n",
    "is_training=graph.get_tensor_by_name(\"training:0\")\n",
    "\n",
    "mypredictions=tf.argmax(stored_y_out,1)\n",
    "print('Test')\n",
    "#predicted result based on input\n",
    "predicted_test=mypredictions.eval(feed_dict={X:X_test,is_training:False}, session=sess)\n",
    "print(predicted_test)\n",
    "print(Y_test)\n",
    "tpr_test,tnr_test=getTPTNRate(Y_test,predicted_test)\n",
    "print(\"true positive rate\",tpr_test,\"true negative rate\",tnr_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the model is based on https://ac.els-cdn.com/S1877705817304289/1-s2.0-S1877705817304289-main.pdf?_tid=918bcd97-2bcc-4ee7-ae31-44ea555c002b&acdnat=1523213163_a7fcbb7625fce5e50f0e1ea690f38c09\n",
    "\n",
    "it has a structure of conv-conv-pool-conv-conv-pool-conv-conv-pool-fc-fc-softmax and each conv layer has a dropout to avoid overfitting\n",
    "\n",
    "however, this model's prediction that has close to 0 true positive rate and close to 1 true negative rate (3 epoch on 1000 training data)\n",
    "\n",
    "the model is improved by adding batch normalization after each conv layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#unused\n",
    "def cnn_model_fn_old(X, labels, is_training):\n",
    "\n",
    "  # Input Layer\n",
    "  # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n",
    "  # MNIST images are 28x28 pixels, and have one color channel\n",
    "    input_layer = tf.reshape(X, [-1, 227, 227, 1])\n",
    "    \n",
    "    \n",
    "#     conv1 = tf.layers.conv2d(\n",
    "#       inputs=input_layer,\n",
    "#       filters=16,\n",
    "#       kernel_size=[11, 11],\n",
    "#       padding=\"same\",\n",
    "#       activation=tf.nn.relu)\n",
    "#     bn1act = tf.layers.batch_normalization(inputs=conv1, training=is_training)\n",
    "#     dropout1 = tf.layers.dropout(\n",
    "#       inputs=bn1act, rate=0.2, training=is_training)\n",
    "#     conv2 = tf.layers.conv2d(\n",
    "#       inputs=dropout1,\n",
    "#       filters=32,\n",
    "#       kernel_size=[5, 5],\n",
    "#       padding=\"same\",\n",
    "#       activation=tf.nn.relu)\n",
    "#     bn2act = tf.layers.batch_normalization(inputs=conv2, training=is_training)\n",
    "#     dropout2 = tf.layers.dropout(\n",
    "#       inputs=bn2act, rate=0.3, training=is_training)\n",
    "#     pool1 = tf.layers.max_pooling2d(inputs=dropout2, pool_size=[3, 3], strides=2)\n",
    "#     conv3 = tf.layers.conv2d(\n",
    "#       inputs=pool1,\n",
    "#       filters=32,\n",
    "#       kernel_size=[5, 5],\n",
    "#       padding=\"same\",\n",
    "#       activation=tf.nn.relu)\n",
    "#     bn3act = tf.layers.batch_normalization(inputs=conv3, training=is_training)\n",
    "#     dropout3 = tf.layers.dropout(\n",
    "#       inputs=bn3act, rate=0.3, training=is_training)\n",
    "#     conv4 = tf.layers.conv2d(\n",
    "#       inputs=dropout3,\n",
    "#       filters=32,\n",
    "#       kernel_size=[3, 3],\n",
    "#       padding=\"same\",\n",
    "#       activation=tf.nn.relu)\n",
    "#     bn4act = tf.layers.batch_normalization(inputs=conv4, training=is_training)\n",
    "#     dropout4 = tf.layers.dropout(\n",
    "#       inputs=bn4act, rate=0.3, training=is_training)\n",
    "#     pool2 = tf.layers.max_pooling2d(inputs=dropout4, pool_size=[3, 3], strides=2)\n",
    "#     conv5 = tf.layers.conv2d(\n",
    "#       inputs=pool2,\n",
    "#       filters=32,\n",
    "#       kernel_size=[3, 3],\n",
    "#       padding=\"same\",\n",
    "#       activation=tf.nn.relu)\n",
    "#     bn5act = tf.layers.batch_normalization(inputs=conv5, training=is_training)\n",
    "#     dropout5 = tf.layers.dropout(\n",
    "#       inputs=bn5act, rate=0.3, training=is_training)\n",
    "#     conv6 = tf.layers.conv2d(\n",
    "#       inputs=dropout5,\n",
    "#       filters=32,\n",
    "#       kernel_size=[3, 3],\n",
    "#       padding=\"same\",\n",
    "#       activation=tf.nn.relu)\n",
    "#     bn6act = tf.layers.batch_normalization(inputs=conv6, training=is_training)\n",
    "#     dropout6 = tf.layers.dropout(\n",
    "#       inputs=bn6act, rate=0.4, training=is_training)\n",
    "#     pool3 = tf.layers.max_pooling2d(inputs=dropout6, pool_size=[3, 3], strides=2)\n",
    "#     pool3_flat = tf.reshape(pool3, [-1, 27 * 27 * 32])\n",
    "#     dense1 = tf.layers.dense(inputs=pool3_flat, units=128, activation=tf.nn.relu)\n",
    "#     dropout6 = tf.layers.dropout(\n",
    "#       inputs=dense1, rate=0.5, training=is_training)\n",
    "#     logits = tf.layers.dense(inputs=dropout6, units=2,activation=None)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "  # Convolutional Layer #1\n",
    "  # Computes 32 features using a 5x5 filter with ReLU activation.\n",
    "  # Padding is added to preserve width and height.\n",
    "  # Input Tensor Shape: [batch_size, 227, 227, 1]\n",
    "  # Output Tensor Shape: [batch_size, 227, 227, 32]\n",
    "    conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=8,\n",
    "      kernel_size=[3, 3],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "    bn1act = tf.layers.batch_normalization(inputs=conv1, training=is_training)\n",
    "\n",
    "  # Pooling Layer #1\n",
    "  # First max pooling layer with a 2x2 filter and stride of 2\n",
    "  # Input Tensor Shape: [batch_size, 227, 227, 32]\n",
    "  # Output Tensor Shape: [batch_size, 113, 113, 32]\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=bn1act, pool_size=[2, 2], strides=2)\n",
    "       \n",
    "\n",
    "  # Flatten tensor into a batch of vectors\n",
    "  # Input Tensor Shape: [batch_size, 56, 56, 64]\n",
    "  # Output Tensor Shape: [batch_size, 56 * 56 * 64]\n",
    "    pool1_flat = tf.reshape(pool1, [-1, 113 * 113 * 8])\n",
    "\n",
    "  # Dense Layer\n",
    "  # Densely connected layer with 1024 neurons\n",
    "  # Input Tensor Shape: [batch_size, 56 * 56 * 64]\n",
    "  # Output Tensor Shape: [batch_size, 1024]\n",
    "    dense = tf.layers.dense(inputs=pool1_flat, units=128, activation=tf.nn.relu)\n",
    "    bn2act = tf.layers.batch_normalization(inputs=dense, training=is_training)\n",
    "\n",
    "  # Add dropout operation; 0.6 probability that element will be kept\n",
    "    dropout = tf.layers.dropout(\n",
    "      inputs=bn2act, rate=0.4, training=is_training)\n",
    "\n",
    "  # Logits layer\n",
    "  # Input Tensor Shape: [batch_size, 1024]\n",
    "  # Output Tensor Shape: [batch_size, 2]\n",
    "    logits = tf.layers.dense(inputs=dropout, units=2,activation=None)\n",
    "\n",
    "#   # Convolutional Layer #2\n",
    "#   # Computes 64 features using a 5x5 filter.\n",
    "#   # Padding is added to preserve width and height.\n",
    "#   # Input Tensor Shape: [batch_size, 113, 113, 32]\n",
    "#   # Output Tensor Shape: [batch_size, 113, 113, 64]\n",
    "#     conv2 = tf.layers.conv2d(\n",
    "#       inputs=pool1,\n",
    "#       filters=64,\n",
    "#       kernel_size=[5, 5],\n",
    "#       padding=\"same\",\n",
    "#       activation=tf.nn.relu)\n",
    "#     bn2act = tf.layers.batch_normalization(inputs=conv2, training=is_training)\n",
    "\n",
    "#   # Pooling Layer #2\n",
    "#   # Second max pooling layer with a 2x2 filter and stride of 2\n",
    "#   # Input Tensor Shape: [batch_size, 113, 113, 64]\n",
    "#   # Output Tensor Shape: [batch_size, 56, 56, 64]\n",
    "#     pool2 = tf.layers.max_pooling2d(inputs=bn2act, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "#     conv3 = tf.layers.conv2d(\n",
    "#       inputs=pool2,\n",
    "#       filters=64,\n",
    "#       kernel_size=[5, 5],\n",
    "#       padding=\"same\",\n",
    "#       activation=tf.nn.relu)\n",
    "#     bn3act = tf.layers.batch_normalization(inputs=conv3, training=is_training)\n",
    "\n",
    "#   # Pooling Layer #2\n",
    "#   # Second max pooling layer with a 2x2 filter and stride of 2\n",
    "#   # Input Tensor Shape: [batch_size, 113, 113, 64]\n",
    "#   # Output Tensor Shape: [batch_size, 56, 56, 64]\n",
    "#     pool2 = tf.layers.max_pooling2d(inputs=bn2act, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "#   # Flatten tensor into a batch of vectors\n",
    "#   # Input Tensor Shape: [batch_size, 56, 56, 64]\n",
    "#   # Output Tensor Shape: [batch_size, 56 * 56 * 64]\n",
    "#     pool2_flat = tf.reshape(pool2, [-1, 56 * 56 * 64])\n",
    "\n",
    "#   # Dense Layer\n",
    "#   # Densely connected layer with 1024 neurons\n",
    "#   # Input Tensor Shape: [batch_size, 56 * 56 * 64]\n",
    "#   # Output Tensor Shape: [batch_size, 1024]\n",
    "#     dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "#     bn3act = tf.layers.batch_normalization(inputs=dense, training=is_training)\n",
    "\n",
    "#   # Add dropout operation; 0.6 probability that element will be kept\n",
    "#     dropout = tf.layers.dropout(\n",
    "#       inputs=bn3act, rate=0.4, training=is_training)\n",
    "\n",
    "#   # Logits layer\n",
    "#   # Input Tensor Shape: [batch_size, 1024]\n",
    "#   # Output Tensor Shape: [batch_size, 2]\n",
    "#     logits = tf.layers.dense(inputs=dropout, units=2,activation=None)\n",
    "    return logits\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with 1000 training data entries 10 epoch, validate with 50 data entries and test with 100 data entries:\n",
    "\n",
    "Validation\n",
    "\n",
    "Epoch 1, Overall loss = 0.247 and accuracy of 0.94\n",
    "\n",
    "Test\n",
    "\n",
    "Epoch 1, Overall loss = 0.298 and accuracy of 0.89\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# new test data\n",
    "## conv-pool-fc(128)-fc-softmax model; training 5 epoches over 4000 data\n",
    "true positive rate 0.6 true negative rate 1.0 (osillating loss)\n",
    "## conv-pool-fc(1024)-fc-softmax model; training 5 epoches over 4000 data\n",
    "true positive rate 0.975 true negative rate 0.975\n",
    "true positive rate 0.5 true negative rate 1.0 (osillating loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old: may have overlapping\n",
    "## conv-pool-fc-fc-softmax model; training 3 epoches over 2000 data\n",
    "validation:true positive rate 0.8 true negative rate 0.975\n",
    "\n",
    "test:true positive rate 0.85 true negative rate 0.99\n",
    "\n",
    "## conv-pool-fc(1024)-fc-softmax model; training 4 epoches over 2000 data\n",
    "validation:true positive rate 0.875 true negative rate 0.975\n",
    "\n",
    "test:true positive rate 0.89 true negative rate 0.96\n",
    "\n",
    "## conv-pool-fc(512)-fc-softmax model; training 4 epoches over 2000 data\n",
    "validation:true positive rate 0.775 true negative rate 0.9\n",
    "\n",
    "test:true positive rate 0.88 true negative rate 0.92\n",
    "\n",
    "## conv-pool-fc(128)-fc-softmax model; training 4 epoches over 2000 data\n",
    "validation:true positive rate 0.925 true negative rate 0.95/true positive rate 0.85 true negative rate 0.925\n",
    "\n",
    "test:true positive rate 0.92 true negative rate 0.99/true positive rate 0.83 true negative rate 0.98\n",
    "\n",
    "## conv-pool-fc(64)-fc-softmax model; training 4 epoches over 2000 data\n",
    "validation:true positive rate 0.8 true negative rate 0.975\n",
    "\n",
    "test:true positive rate 0.88 true negative rate 0.97\n",
    "\n",
    "## conv-pool-fc-fc-softmax model; training 4 epoches over 4000 data\n",
    "validation:true positive rate 0.925 true negative rate 1.0\n",
    "\n",
    "test:true positive rate 0.94 true negative rate 0.98\n",
    "\n",
    "## conv-pool-conv-pool-conv-pool-fc-fc-softmax model; training 3 epoches over 1000 data\n",
    "\n",
    "validation:true positive rate 0.9 true negative rate 0.95\n",
    "\n",
    "test:true positive rate 0.91 true negative rate 0.96\n",
    "\n",
    "## conv-pool-conv-pool-conv-pool-fc-fc-softmax model; training 4 epoches over 2000 data\n",
    "validation:true positive rate 0.975 true negative rate 0.95\n",
    "\n",
    "test:true positive rate 0.95 true negative rate 0.93\n",
    "\n",
    "## conv-conv-pool-conv-conv-pool-conv-conv-pool-fc-fc-softmax model; training 3 epoches over 1000 data\n",
    "\n",
    "validation: true positive rate 0.9 true negative rate 0.95\n",
    "\n",
    "test: true positive rate 0.96 true negative rate 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
