{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/tutorials/layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import sys\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import pylab as pl\n",
    "import math\n",
    "\n",
    "# This is a bit of magic to make matplotlib figures appear inline in the notebook\n",
    "# rather than in a new window.\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocess the image by adding filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_fn(X, labels, is_training):\n",
    "\n",
    "  # Input Layer\n",
    "  # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n",
    "  # MNIST images are 28x28 pixels, and have one color channel\n",
    "    input_layer = tf.reshape(X, [-1, 227, 227, 1])\n",
    "\n",
    "  # Convolutional Layer #1\n",
    "  # Computes 32 features using a 5x5 filter with ReLU activation.\n",
    "  # Padding is added to preserve width and height.\n",
    "  # Input Tensor Shape: [batch_size, 227, 227, 1]\n",
    "  # Output Tensor Shape: [batch_size, 227, 227, 32]\n",
    "    conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=32,\n",
    "      kernel_size=[3, 3],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "    bn1act = tf.layers.batch_normalization(inputs=conv1, training=is_training)\n",
    "\n",
    "  # Pooling Layer #1\n",
    "  # First max pooling layer with a 2x2 filter and stride of 2\n",
    "  # Input Tensor Shape: [batch_size, 227, 227, 32]\n",
    "  # Output Tensor Shape: [batch_size, 113, 113, 32]\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=bn1act, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Convolutional Layer #2\n",
    "  # Computes 64 features using a 5x5 filter.\n",
    "  # Padding is added to preserve width and height.\n",
    "  # Input Tensor Shape: [batch_size, 113, 113, 32]\n",
    "  # Output Tensor Shape: [batch_size, 113, 113, 64]\n",
    "    conv2 = tf.layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      filters=64,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "    bn2act = tf.layers.batch_normalization(inputs=conv2, training=is_training)\n",
    "\n",
    "  # Pooling Layer #2\n",
    "  # Second max pooling layer with a 2x2 filter and stride of 2\n",
    "  # Input Tensor Shape: [batch_size, 113, 113, 64]\n",
    "  # Output Tensor Shape: [batch_size, 56, 56, 64]\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=bn2act, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Flatten tensor into a batch of vectors\n",
    "  # Input Tensor Shape: [batch_size, 56, 56, 64]\n",
    "  # Output Tensor Shape: [batch_size, 56 * 56 * 64]\n",
    "    pool2_flat = tf.reshape(pool2, [-1, 56 * 56 * 64])\n",
    "\n",
    "  # Dense Layer\n",
    "  # Densely connected layer with 1024 neurons\n",
    "  # Input Tensor Shape: [batch_size, 56 * 56 * 64]\n",
    "  # Output Tensor Shape: [batch_size, 1024]\n",
    "    dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "    bn3act = tf.layers.batch_normalization(inputs=dense, training=is_training)\n",
    "\n",
    "  # Add dropout operation; 0.6 probability that element will be kept\n",
    "    dropout = tf.layers.dropout(\n",
    "      inputs=bn3act, rate=0.4, training=is_training)\n",
    "\n",
    "  # Logits layer\n",
    "  # Input Tensor Shape: [batch_size, 1024]\n",
    "  # Output Tensor Shape: [batch_size, 2]\n",
    "    logits = tf.layers.dense(inputs=dropout, units=2,activation=None)\n",
    "    return logits\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#   predictions = {\n",
    "#       # Generate predictions (for PREDICT and EVAL mode)\n",
    "#       \"classes\": tf.argmax(input=logits, axis=1),\n",
    "#       # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "#       # `logging_hook`.\n",
    "#       \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "#   }\n",
    "#   if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "#     return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "  # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "#   loss = tf.losses.sparse_softmax_cross_entropy(labels=y, logits=logits)\n",
    "\n",
    "#   # Configure the Training Op (for TRAIN mode)\n",
    "#   if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "#     optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "#     train_op = optimizer.minimize(\n",
    "#         loss=loss,\n",
    "#         global_step=tf.train.get_global_step())\n",
    "#     return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "#   # Add evaluation metrics (for EVAL mode)\n",
    "#   eval_metric_ops = {\n",
    "#       \"accuracy\": tf.metrics.accuracy(\n",
    "#           labels=labels, predictions=predictions[\"classes\"])}\n",
    "#   return tf.estimator.EstimatorSpec(\n",
    "#       mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "#   train_data = mnist.train.images  # Returns np.array\n",
    "#   train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "#   eval_data = mnist.test.images  # Returns np.array\n",
    "#   eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n",
    "\n",
    "#   # Create the Estimator\n",
    "#   mnist_classifier = tf.estimator.Estimator(\n",
    "#       model_fn=cnn_model_fn, model_dir=\"/tmp/mnist_convnet_model\")\n",
    "\n",
    "#   # Set up logging for predictions\n",
    "#   # Log the values in the \"Softmax\" tensor with label \"probabilities\"\n",
    "#   tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "#   logging_hook = tf.train.LoggingTensorHook(\n",
    "#       tensors=tensors_to_log, every_n_iter=50)\n",
    "\n",
    "#   # Train the model\n",
    "#   train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "#       x={\"x\": train_data},\n",
    "#       y=train_labels,\n",
    "#       batch_size=100,\n",
    "#       num_epochs=None,\n",
    "#       shuffle=True)\n",
    "#   mnist_classifier.train(\n",
    "#       input_fn=train_input_fn,\n",
    "#       steps=20000,\n",
    "#       hooks=[logging_hook])\n",
    "\n",
    "#   # Evaluate the model and print results\n",
    "#   eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "#       x={\"x\": eval_data},\n",
    "#       y=eval_labels,\n",
    "#       num_epochs=1,\n",
    "#       shuffle=False)\n",
    "#   eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "#   print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_grayscale(image, beta=0.75, image_id_k = 1, A_kp=None):\n",
    "    N,M = image.shape\n",
    "    k = image_id_k\n",
    "    \n",
    "    if image_id_k > 1 and  A_kp is None :\n",
    "        print(\"please define A_kp as this is not the first image\")\n",
    "    elif image_id_k == 1:\n",
    "        A_kp = np.zeros((N,M))\n",
    "        \n",
    "    alpha = beta*(k-1)/k\n",
    "    a = np.mean(image, axis=0)\n",
    "    A_k = alpha*A_kp + (1-alpha)*np.tile(a,(N,1))\n",
    "    image = 128*(image/A_k)\n",
    "    return image, A_k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# features={\"x_train\":X_train}\n",
    "# labels=Y_train\n",
    "# def train_input_fn(features, labels, batch_size):\n",
    "#     \"\"\"An input function for training\"\"\"\n",
    "#     # Convert the inputs to a Dataset.\n",
    "#     dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "\n",
    "#     # Shuffle, repeat, and batch the examples.\n",
    "#     dataset = dataset.shuffle(1000).repeat().batch(batch_size)\n",
    "\n",
    "#     # Build the Iterator, and return the read end of the pipeline.\n",
    "#     return dataset.make_one_shot_iterator().get_next()\n",
    "# features_result,labels_result=train_input_fn(features, labels, 10)    \n",
    "\n",
    "\n",
    "def run_model(session, predict, loss_val, Xd, yd,\n",
    "              epochs=1, batch_size=64, print_every=100,\n",
    "              training=None, plot_losses=False):\n",
    "    \n",
    "    # have tensorflow compute accuracy\n",
    "    correct_prediction = tf.equal(tf.argmax(predict,1), y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    train_indicies = np.arange(Xd.shape[0])\n",
    "    \n",
    "    training_now = (training is not None)\n",
    "    \n",
    "    # setting up variables we want to compute (and optimizing)\n",
    "    # if we have a training function, add that to things we compute\n",
    "    variables = [mean_loss, correct_prediction, accuracy]\n",
    "    if training_now:\n",
    "        variables[-1] = training\n",
    "\n",
    "    # counter \n",
    "    iter_cnt = 0\n",
    "    # keep track of losses\n",
    "    losses = []\n",
    "    for e in range(epochs):\n",
    "        # shuffle indicies\n",
    "        np.random.shuffle(train_indicies)\n",
    "        # keep track of accuracy\n",
    "        correct = 0\n",
    "        # make sure we iterate over the dataset once\n",
    "        for i in range(int(math.ceil(Xd.shape[0]/batch_size))):\n",
    "            # generate indicies for the batch\n",
    "            start_idx = (i*batch_size)%Xd.shape[0]\n",
    "            idx = train_indicies[start_idx:start_idx+batch_size]\n",
    "            \n",
    "            # create a feed dictionary for this batch\n",
    "            feed_dict = {X: Xd[idx,:],\n",
    "                         y: yd[idx],\n",
    "                         is_training: training_now }\n",
    "            # get batch size\n",
    "            actual_batch_size = yd[idx].shape[0]\n",
    "            \n",
    "            # have tensorflow compute loss and correct predictions\n",
    "            # and (if given) perform a training step\n",
    "            loss, corr, _ = session.run(variables,feed_dict=feed_dict)\n",
    "            corr = np.array(corr).astype(np.float32)\n",
    "            \n",
    "            # aggregate performance stats\n",
    "            losses.append(loss*actual_batch_size)\n",
    "            correct += np.sum(corr)\n",
    "            \n",
    "            # print every now and then\n",
    "            if training_now and (iter_cnt % print_every) == 0:\n",
    "                print(\"Iteration {0}: with minibatch training loss = {1:.3g} and accuracy of {2:.2g}\"\\\n",
    "                      .format(iter_cnt,loss,np.sum(corr)/actual_batch_size))\n",
    "            iter_cnt += 1\n",
    "        total_correct = correct/Xd.shape[0]\n",
    "        total_loss = np.sum(losses)/Xd.shape[0]\n",
    "        print(\"Epoch {2}, Overall loss = {0:.3g} and accuracy of {1:.3g}\"\\\n",
    "              .format(total_loss,total_correct,e+1))\n",
    "        \n",
    "    if plot_losses:\n",
    "        plt.plot(losses)\n",
    "        plt.grid(True)\n",
    "        plt.title('Epoch {} Loss'.format(e+1))\n",
    "        plt.xlabel('minibatch number')\n",
    "        plt.ylabel('minibatch loss')\n",
    "        plt.show()\n",
    "            \n",
    "    return total_loss,total_correct,losses\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 227, 227])\n",
    "y = tf.placeholder(tf.int64, [None])\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "y_out = cnn_model_fn(X,y,is_training)\n",
    "total_loss = tf.losses.softmax_cross_entropy(logits=y_out, onehot_labels=tf.one_hot(y,2))\n",
    "mean_loss = tf.reduce_mean(total_loss)\n",
    "optimizer = tf.train.AdamOptimizer(1e-4) #adam\n",
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(extra_update_ops):\n",
    "    train_step = optimizer.minimize(mean_loss)\n",
    "\n",
    "# txt = '../Negative/00001.jpg'\n",
    "# img = cv2.imread(txt, 0).astype(np.float32)\n",
    "# print(img2.shape)\n",
    "# plt.figure(figsize=(10,5))\n",
    "# plt.subplot(121),plt.imshow(img, cmap='gray')\n",
    "# plt.title('Original'),plt.xticks([]),plt.yticks([])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess = tf.Session()\n",
    "\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "# print('Training')\n",
    "# run_model(sess,y_out,mean_loss,X_train,Y_train,10,64,100,train_step,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Validation')\n",
    "# run_model(sess,y_out,mean_loss,X_val,Y_val,1,64)\n",
    "# print('Test')\n",
    "# run_model(sess,y_out,mean_loss,X_test,Y_test,1,64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with 1000 training data entries 10 epoch, validate with 50 data entries and test with 100 data entries:\n",
    "\n",
    "Validation\n",
    "\n",
    "Epoch 1, Overall loss = 0.247 and accuracy of 0.94\n",
    "\n",
    "Test\n",
    "\n",
    "Epoch 1, Overall loss = 0.298 and accuracy of 0.89\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: test the accuracy on positive and negative \n",
    "## add filter and train again (with maybe 500 data entries for training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_model_TF(session, predict, loss_val, Xd, yd,\n",
    "              epochs=1, batch_size=64, print_every=100,\n",
    "              training=None, plot_losses=False):\n",
    "    \n",
    "    # have tensorflow compute accuracy\n",
    "    predictions=tf.argmax(predict,1)\n",
    "    actuals=y \n",
    "    ones_like_actuals = tf.ones_like(actuals)\n",
    "    zeros_like_actuals = tf.zeros_like(actuals)\n",
    "    ones_like_predictions = tf.ones_like(predictions)\n",
    "    zeros_like_predictions = tf.zeros_like(predictions)\n",
    "    tp_op = tf.reduce_sum(\n",
    "    tf.cast(\n",
    "      tf.logical_and(\n",
    "        tf.equal(actuals, ones_like_actuals), \n",
    "        tf.equal(predictions, ones_like_predictions)\n",
    "      ), \n",
    "      \"float\"\n",
    "    )\n",
    "  )\n",
    "    tn_op = tf.reduce_sum(\n",
    "    tf.cast(\n",
    "      tf.logical_and(\n",
    "        tf.equal(actuals, zeros_like_actuals), \n",
    "        tf.equal(predictions, zeros_like_predictions)\n",
    "      ), \n",
    "      \"float\"\n",
    "    )\n",
    "  )\n",
    "    fp_op = tf.reduce_sum(\n",
    "    tf.cast(\n",
    "      tf.logical_and(\n",
    "        tf.equal(actuals, zeros_like_actuals), \n",
    "        tf.equal(predictions, ones_like_predictions)\n",
    "      ), \n",
    "      \"float\"\n",
    "    )\n",
    "  )\n",
    "    fn_op = tf.reduce_sum(\n",
    "    tf.cast(\n",
    "      tf.logical_and(\n",
    "        tf.equal(actuals, ones_like_actuals), \n",
    "        tf.equal(predictions, zeros_like_predictions)\n",
    "      ), \n",
    "      \"float\"\n",
    "    )\n",
    "  )\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     correct_prediction = tf.equal(tf.argmax(predict,1), y)\n",
    "#     accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    \n",
    "    train_indicies = np.arange(Xd.shape[0])\n",
    "    \n",
    "    training_now = (training is not None)\n",
    "    \n",
    "    # setting up variables we want to compute (and optimizing)\n",
    "    # if we have a training function, add that to things we compute\n",
    "    variables = [mean_loss, tp_op, tn_op, fp_op, fn_op]\n",
    "    if training_now:\n",
    "        variables[-1] = training\n",
    "\n",
    "    # counter \n",
    "    iter_cnt = 0\n",
    "    # keep track of losses\n",
    "    losses = []\n",
    "    tprs=[]\n",
    "    tnrs=[]\n",
    "    for e in range(epochs):\n",
    "        # shuffle indicies\n",
    "        np.random.shuffle(train_indicies)\n",
    "\n",
    "        # make sure we iterate over the dataset once\n",
    "        for i in range(int(math.ceil(Xd.shape[0]/batch_size))):\n",
    "            # generate indicies for the batch\n",
    "            start_idx = (i*batch_size)%Xd.shape[0]\n",
    "            idx = train_indicies[start_idx:start_idx+batch_size]\n",
    "            \n",
    "            # create a feed dictionary for this batch\n",
    "            feed_dict = {X: Xd[idx,:],\n",
    "                         y: yd[idx],\n",
    "                         is_training: training_now }\n",
    "            # get batch size\n",
    "            actual_batch_size = yd[idx].shape[0]\n",
    "            \n",
    "            # have tensorflow compute loss and correct predictions\n",
    "            # and (if given) perform a training step\n",
    "            loss, tp, tn, fp, fn = session.run(variables,feed_dict=feed_dict)\n",
    "\n",
    "            if fn is None:\n",
    "                fn=actual_batch_size-tp-tn-fp\n",
    "   \n",
    "            print(tp,tn,fp,fn)\n",
    "            tpr = float(tp)/(float(tp) + float(fn))\n",
    "            fpr = float(fp)/(float(tp) + float(fn))\n",
    "            tnr=float(tn)/(float(tn) + float(fp))\n",
    "            accuracy = (float(tp) + float(tn))/(float(tp) + float(fp) + float(fn) + float(tn))\n",
    "            \n",
    "            recall = tpr\n",
    "            precision = float(tp)/(float(tp) + float(fp))\n",
    "            f1_score = (2 * (precision * recall)) / (precision + recall)\n",
    "            \n",
    "            # aggregate performance stats\n",
    "            losses.append(loss*actual_batch_size)\n",
    "            tprs.append(tpr)\n",
    "            tnrs.append(tnr)\n",
    "\n",
    "            \n",
    "            # print every now and then\n",
    "            if training_now and (iter_cnt % print_every) == 0:\n",
    "                print(\"Iteration {0}: with minibatch training loss = {1:.3g},tpr of {2:.2g} and tnr of {3:.2g}\"\\\n",
    "                      .format(iter_cnt,loss,tpr,tnr))\n",
    "            iter_cnt += 1\n",
    "        total_tpr = np.sum(tprs)/iter_cnt\n",
    "        total_tnr=np.sum(tnrs)/iter_cnt\n",
    "        total_loss = np.sum(losses)/Xd.shape[0]\n",
    "        print(len(tprs),tprs)\n",
    "        print(len(tnrs),tnrs)\n",
    "\n",
    "        print(\"Epoch {3}, Overall loss = {0:.3g} tpr of {1:.3g} and tnr of {2:.3g}\"\\\n",
    "              .format(total_loss,total_tpr,total_tnr,e+1))\n",
    "        \n",
    "    if plot_losses:\n",
    "        plt.plot(losses)\n",
    "        plt.grid(True)\n",
    "        plt.title('Epoch {} Loss'.format(e+1))\n",
    "        plt.xlabel('minibatch number')\n",
    "        plt.ylabel('minibatch loss')\n",
    "        plt.show()\n",
    "            \n",
    "    return total_loss,total_tpr,total_tnr,losses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read the data\n",
    "#train 500 negatives and 500 positives\n",
    "#use 50 negatives and 50 positives to validate\n",
    "#100 negatives and 100 positives to test\n",
    "X_train=[]\n",
    "Y_train=[]\n",
    "X_test=[]\n",
    "Y_test=[] \n",
    "X_val=[]\n",
    "Y_val=[]  \n",
    "\n",
    "for i in range(1,501):\n",
    "    j  = i + 1600\n",
    "    txt = '../Positive/0'+str(j).zfill(4)+'.jpg'\n",
    "    img = cv2.imread(txt, 0).astype(np.float32)\n",
    "    X_train.append(img)\n",
    "    Y_train.append(1)\n",
    "\n",
    "for i in range(1,501):\n",
    "    j  = i + 1600\n",
    "    txt = '../Negative/0'+str(j).zfill(4)+'.jpg'\n",
    "    img = cv2.imread(txt, 0).astype(np.float32)\n",
    "    X_train.append(img)\n",
    "    Y_train.append(0)\n",
    "    \n",
    "for i in range(1,41):\n",
    "    j  = i + 1000\n",
    "    txt = '../Positive/1'+str(i).zfill(4)+'_1.jpg'\n",
    "    img = cv2.imread(txt, 0).astype(np.float32)\n",
    "    X_val.append(img)\n",
    "    Y_val.append(1)\n",
    "\n",
    "for i in range(1,41):\n",
    "    j  = i + 1000\n",
    "    txt = '../Negative/1'+str(i).zfill(4)+'.jpg'\n",
    "    img = cv2.imread(txt, 0).astype(np.float32)\n",
    "    X_val.append(img)\n",
    "    Y_val.append(0)\n",
    "\n",
    "   \n",
    "for i in range(1,101):\n",
    "    j  = i + 1000\n",
    "    txt = '../Positive/1'+str(j).zfill(4)+'_1.jpg'\n",
    "    img = cv2.imread(txt, 0).astype(np.float32)\n",
    "    X_test.append(img)\n",
    "    Y_test.append(1)\n",
    "\n",
    "for i in range(1,101):\n",
    "    j  = i + 1000\n",
    "    txt = '../Negative/1'+str(j).zfill(4)+'.jpg'\n",
    "    img = cv2.imread(txt, 0).astype(np.float32)\n",
    "    X_test.append(img)\n",
    "    Y_test.append(0)\n",
    "\n",
    "X_test=np.asarray(X_test)\n",
    "Y_test=np.asarray(Y_test)    \n",
    "X_val=np.asarray(X_val)\n",
    "Y_val=np.asarray(Y_val)\n",
    "X_train=np.asarray(X_train)\n",
    "Y_train=np.asarray(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "13.0 12.0 22.0 17.0\n",
      "Iteration 0: with minibatch training loss = 1.45,tpr of 0.43 and tnr of 0.35\n",
      "24.0 26.0 6.0 8.0\n",
      "28.0 26.0 1.0 9.0\n",
      "28.0 31.0 1.0 4.0\n",
      "26.0 31.0 1.0 6.0\n",
      "24.0 34.0 3.0 3.0\n",
      "22.0 34.0 2.0 6.0\n",
      "24.0 34.0 0.0 6.0\n",
      "26.0 30.0 1.0 7.0\n",
      "32.0 24.0 1.0 7.0\n",
      "29.0 30.0 2.0 3.0\n",
      "31.0 26.0 0.0 7.0\n",
      "30.0 29.0 3.0 2.0\n",
      "23.0 35.0 1.0 5.0\n",
      "28.0 33.0 1.0 2.0\n",
      "16.0 18.0 2.0 4.0\n",
      "16 [0.43333333333333335, 0.75, 0.7567567567567568, 0.875, 0.8125, 0.8888888888888888, 0.7857142857142857, 0.8, 0.7878787878787878, 0.8205128205128205, 0.90625, 0.8157894736842105, 0.9375, 0.8214285714285714, 0.9333333333333333, 0.8]\n",
      "16 [0.35294117647058826, 0.8125, 0.9629629629629629, 0.96875, 0.96875, 0.918918918918919, 0.9444444444444444, 1.0, 0.967741935483871, 0.96, 0.9375, 1.0, 0.90625, 0.9722222222222222, 0.9705882352941176, 0.9]\n",
      "Epoch 1, Overall loss = 0.75 tpr of 0.808 and tnr of 0.909\n",
      "32.0 29.0 2.0 1.0\n",
      "30.0 31.0 1.0 2.0\n",
      "28.0 33.0 2.0 1.0\n",
      "30.0 31.0 2.0 1.0\n",
      "32.0 29.0 2.0 1.0\n",
      "35.0 26.0 0.0 3.0\n",
      "36.0 26.0 0.0 2.0\n",
      "30.0 30.0 0.0 4.0\n",
      "28.0 35.0 0.0 1.0\n",
      "32.0 32.0 0.0 0.0\n",
      "30.0 32.0 0.0 2.0\n",
      "27.0 37.0 0.0 0.0\n",
      "35.0 27.0 1.0 1.0\n",
      "25.0 35.0 3.0 1.0\n",
      "34.0 29.0 0.0 1.0\n",
      "15.0 21.0 4.0 0.0\n",
      "32 [0.43333333333333335, 0.75, 0.7567567567567568, 0.875, 0.8125, 0.8888888888888888, 0.7857142857142857, 0.8, 0.7878787878787878, 0.8205128205128205, 0.90625, 0.8157894736842105, 0.9375, 0.8214285714285714, 0.9333333333333333, 0.8, 0.9696969696969697, 0.9375, 0.9655172413793104, 0.967741935483871, 0.9696969696969697, 0.9210526315789473, 0.9473684210526315, 0.8823529411764706, 0.9655172413793104, 1.0, 0.9375, 1.0, 0.9722222222222222, 0.9615384615384616, 0.9714285714285714, 1.0]\n",
      "32 [0.35294117647058826, 0.8125, 0.9629629629629629, 0.96875, 0.96875, 0.918918918918919, 0.9444444444444444, 1.0, 0.967741935483871, 0.96, 0.9375, 1.0, 0.90625, 0.9722222222222222, 0.9705882352941176, 0.9, 0.9354838709677419, 0.96875, 0.9428571428571428, 0.9393939393939394, 0.9354838709677419, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9642857142857143, 0.9210526315789473, 1.0, 0.84]\n",
      "Epoch 2, Overall loss = 0.89 tpr of 0.884 and tnr of 0.937\n",
      "23.0 38.0 2.0 1.0\n",
      "31.0 33.0 0.0 0.0\n",
      "31.0 33.0 0.0 0.0\n",
      "27.0 36.0 1.0 0.0\n",
      "30.0 34.0 0.0 0.0\n",
      "36.0 27.0 0.0 1.0\n",
      "29.0 33.0 0.0 2.0\n",
      "28.0 35.0 0.0 1.0\n",
      "33.0 30.0 0.0 1.0\n",
      "33.0 30.0 0.0 1.0\n",
      "32.0 32.0 0.0 0.0\n",
      "29.0 34.0 0.0 1.0\n",
      "38.0 23.0 0.0 3.0\n",
      "32.0 32.0 0.0 0.0\n",
      "33.0 30.0 0.0 1.0\n",
      "21.0 17.0 0.0 2.0\n",
      "48 [0.43333333333333335, 0.75, 0.7567567567567568, 0.875, 0.8125, 0.8888888888888888, 0.7857142857142857, 0.8, 0.7878787878787878, 0.8205128205128205, 0.90625, 0.8157894736842105, 0.9375, 0.8214285714285714, 0.9333333333333333, 0.8, 0.9696969696969697, 0.9375, 0.9655172413793104, 0.967741935483871, 0.9696969696969697, 0.9210526315789473, 0.9473684210526315, 0.8823529411764706, 0.9655172413793104, 1.0, 0.9375, 1.0, 0.9722222222222222, 0.9615384615384616, 0.9714285714285714, 1.0, 0.9583333333333334, 1.0, 1.0, 1.0, 1.0, 0.972972972972973, 0.9354838709677419, 0.9655172413793104, 0.9705882352941176, 0.9705882352941176, 1.0, 0.9666666666666667, 0.926829268292683, 1.0, 0.9705882352941176, 0.9130434782608695]\n",
      "48 [0.35294117647058826, 0.8125, 0.9629629629629629, 0.96875, 0.96875, 0.918918918918919, 0.9444444444444444, 1.0, 0.967741935483871, 0.96, 0.9375, 1.0, 0.90625, 0.9722222222222222, 0.9705882352941176, 0.9, 0.9354838709677419, 0.96875, 0.9428571428571428, 0.9393939393939394, 0.9354838709677419, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9642857142857143, 0.9210526315789473, 1.0, 0.84, 0.95, 1.0, 1.0, 0.972972972972973, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Epoch 3, Overall loss = 0.949 tpr of 0.913 and tnr of 0.957\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmgAAAHwCAYAAAASMpP6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nISTiKzQIPJAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x130b60d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n",
      "31.0 0.0 33.0 0.0\n",
      "9.0 0.0 7.0 0.0\n",
      "2 [1.0, 1.0]\n",
      "2 [0.0, 0.0]\n",
      "Epoch 1, Overall loss = 1.9 tpr of 1 and tnr of 0\n",
      "Test\n",
      "29.0 0.0 35.0 0.0\n",
      "36.0 0.0 28.0 0.0\n",
      "29.0 0.0 35.0 0.0\n",
      "6.0 0.0 2.0 0.0\n",
      "4 [1.0, 1.0, 1.0, 1.0]\n",
      "4 [0.0, 0.0, 0.0, 0.0]\n",
      "Epoch 1, Overall loss = 2.08 tpr of 1 and tnr of 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.0760224533081053,\n",
       " 1.0,\n",
       " 0.0,\n",
       " [147.51101684570312,\n",
       "  117.03327941894531,\n",
       "  141.89506530761719,\n",
       "  8.7651290893554688])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print('Training')\n",
    "run_model_TF(sess,y_out,mean_loss,X_train,Y_train,3,64,100,train_step,True)\n",
    "print('Validation')\n",
    "run_model_TF(sess,y_out,mean_loss,X_val,Y_val,1,64)\n",
    "print('Test')\n",
    "run_model_TF(sess,y_out,mean_loss,X_test,Y_test,1,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
