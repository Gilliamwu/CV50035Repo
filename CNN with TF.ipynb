{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/tutorials/layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import sys\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import pylab as pl\n",
    "import math\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# This is a bit of magic to make matplotlib figures appear inline in the notebook\n",
    "# rather than in a new window.\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocess the image by adding filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnn_model_fn(X, labels, is_training):\n",
    "\n",
    "  # Input Layer\n",
    "  # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n",
    "  # MNIST images are 28x28 pixels, and have one color channel\n",
    "    input_layer = tf.reshape(X, [-1, 227, 227, 1])\n",
    "\n",
    "  # Convolutional Layer #1\n",
    "  # Computes 32 features using a 5x5 filter with ReLU activation.\n",
    "  # Padding is added to preserve width and height.\n",
    "  # Input Tensor Shape: [batch_size, 227, 227, 1]\n",
    "  # Output Tensor Shape: [batch_size, 227, 227, 32]\n",
    "    conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=32,\n",
    "      kernel_size=[3, 3],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "    bn1act = tf.layers.batch_normalization(inputs=conv1, training=is_training)\n",
    "\n",
    "  # Pooling Layer #1\n",
    "  # First max pooling layer with a 2x2 filter and stride of 2\n",
    "  # Input Tensor Shape: [batch_size, 227, 227, 32]\n",
    "  # Output Tensor Shape: [batch_size, 113, 113, 32]\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=bn1act, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Convolutional Layer #2\n",
    "  # Computes 64 features using a 5x5 filter.\n",
    "  # Padding is added to preserve width and height.\n",
    "  # Input Tensor Shape: [batch_size, 113, 113, 32]\n",
    "  # Output Tensor Shape: [batch_size, 113, 113, 64]\n",
    "    conv2 = tf.layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      filters=64,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "    bn2act = tf.layers.batch_normalization(inputs=conv2, training=is_training)\n",
    "\n",
    "  # Pooling Layer #2\n",
    "  # Second max pooling layer with a 2x2 filter and stride of 2\n",
    "  # Input Tensor Shape: [batch_size, 113, 113, 64]\n",
    "  # Output Tensor Shape: [batch_size, 56, 56, 64]\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=bn2act, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Flatten tensor into a batch of vectors\n",
    "  # Input Tensor Shape: [batch_size, 56, 56, 64]\n",
    "  # Output Tensor Shape: [batch_size, 56 * 56 * 64]\n",
    "    pool2_flat = tf.reshape(pool2, [-1, 56 * 56 * 64])\n",
    "\n",
    "  # Dense Layer\n",
    "  # Densely connected layer with 1024 neurons\n",
    "  # Input Tensor Shape: [batch_size, 56 * 56 * 64]\n",
    "  # Output Tensor Shape: [batch_size, 1024]\n",
    "    dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "    bn3act = tf.layers.batch_normalization(inputs=dense, training=is_training)\n",
    "\n",
    "  # Add dropout operation; 0.6 probability that element will be kept\n",
    "    dropout = tf.layers.dropout(\n",
    "      inputs=bn3act, rate=0.4, training=is_training)\n",
    "\n",
    "  # Logits layer\n",
    "  # Input Tensor Shape: [batch_size, 1024]\n",
    "  # Output Tensor Shape: [batch_size, 2]\n",
    "    logits = tf.layers.dense(inputs=dropout, units=2,activation=None)\n",
    "    return logits\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#   predictions = {\n",
    "#       # Generate predictions (for PREDICT and EVAL mode)\n",
    "#       \"classes\": tf.argmax(input=logits, axis=1),\n",
    "#       # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "#       # `logging_hook`.\n",
    "#       \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "#   }\n",
    "#   if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "#     return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "  # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "#   loss = tf.losses.sparse_softmax_cross_entropy(labels=y, logits=logits)\n",
    "\n",
    "#   # Configure the Training Op (for TRAIN mode)\n",
    "#   if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "#     optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "#     train_op = optimizer.minimize(\n",
    "#         loss=loss,\n",
    "#         global_step=tf.train.get_global_step())\n",
    "#     return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "#   # Add evaluation metrics (for EVAL mode)\n",
    "#   eval_metric_ops = {\n",
    "#       \"accuracy\": tf.metrics.accuracy(\n",
    "#           labels=labels, predictions=predictions[\"classes\"])}\n",
    "#   return tf.estimator.EstimatorSpec(\n",
    "#       mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#   mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "#   train_data = mnist.train.images  # Returns np.array\n",
    "#   train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "#   eval_data = mnist.test.images  # Returns np.array\n",
    "#   eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n",
    "\n",
    "#   # Create the Estimator\n",
    "#   mnist_classifier = tf.estimator.Estimator(\n",
    "#       model_fn=cnn_model_fn, model_dir=\"/tmp/mnist_convnet_model\")\n",
    "\n",
    "#   # Set up logging for predictions\n",
    "#   # Log the values in the \"Softmax\" tensor with label \"probabilities\"\n",
    "#   tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "#   logging_hook = tf.train.LoggingTensorHook(\n",
    "#       tensors=tensors_to_log, every_n_iter=50)\n",
    "\n",
    "#   # Train the model\n",
    "#   train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "#       x={\"x\": train_data},\n",
    "#       y=train_labels,\n",
    "#       batch_size=100,\n",
    "#       num_epochs=None,\n",
    "#       shuffle=True)\n",
    "#   mnist_classifier.train(\n",
    "#       input_fn=train_input_fn,\n",
    "#       steps=20000,\n",
    "#       hooks=[logging_hook])\n",
    "\n",
    "#   # Evaluate the model and print results\n",
    "#   eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "#       x={\"x\": eval_data},\n",
    "#       y=eval_labels,\n",
    "#       num_epochs=1,\n",
    "#       shuffle=False)\n",
    "#   eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "#   print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_grayscale(image, beta=0.75, image_id_k = 1, A_kp=None):\n",
    "    N,M = image.shape\n",
    "    k = image_id_k\n",
    "    \n",
    "    if image_id_k > 1 and  A_kp is None :\n",
    "        print(\"please define A_kp as this is not the first image\")\n",
    "    elif image_id_k == 1:\n",
    "        A_kp = np.zeros((N,M))\n",
    "        \n",
    "    alpha = beta*(k-1)/k\n",
    "    a = np.mean(image, axis=0)\n",
    "    A_k = alpha*A_kp + (1-alpha)*np.tile(a,(N,1))\n",
    "    image = 128*(image/A_k)\n",
    "    return image, A_k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_model(session, predict, loss_val, Xd, yd,\n",
    "              epochs=1, batch_size=64, print_every=100,\n",
    "              training=None, plot_losses=False):\n",
    "    \n",
    "    # have tensorflow compute accuracy\n",
    "    correct_prediction = tf.equal(tf.argmax(predict,1), y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    train_indicies = np.arange(Xd.shape[0])\n",
    "    \n",
    "    training_now = (training is not None)\n",
    "    \n",
    "    # setting up variables we want to compute (and optimizing)\n",
    "    # if we have a training function, add that to things we compute\n",
    "    variables = [mean_loss, correct_prediction, accuracy]\n",
    "    if training_now:\n",
    "        variables[-1] = training\n",
    "\n",
    "    # counter \n",
    "    iter_cnt = 0\n",
    "    # keep track of losses\n",
    "    losses = []\n",
    "    for e in range(epochs):\n",
    "        # shuffle indicies\n",
    "        np.random.shuffle(train_indicies)\n",
    "        # keep track of accuracy\n",
    "        correct = 0\n",
    "        # make sure we iterate over the dataset once\n",
    "        for i in range(int(math.ceil(Xd.shape[0]/batch_size))):\n",
    "            # generate indicies for the batch\n",
    "            start_idx = (i*batch_size)%Xd.shape[0]\n",
    "            idx = train_indicies[start_idx:start_idx+batch_size]\n",
    "            \n",
    "            # create a feed dictionary for this batch\n",
    "            feed_dict = {X: Xd[idx,:],\n",
    "                         y: yd[idx],\n",
    "                         is_training: training_now }\n",
    "            # get batch size\n",
    "            actual_batch_size = yd[idx].shape[0]\n",
    "            \n",
    "            # have tensorflow compute loss and correct predictions\n",
    "            # and (if given) perform a training step\n",
    "            loss, corr, _ = session.run(variables,feed_dict=feed_dict)\n",
    "            corr = np.array(corr).astype(np.float32)\n",
    "            \n",
    "            # aggregate performance stats\n",
    "            losses.append(loss*actual_batch_size)\n",
    "            correct += np.sum(corr)\n",
    "            \n",
    "            # print every now and then\n",
    "            if training_now and (iter_cnt % print_every) == 0:\n",
    "                print(\"Iteration {0}: with minibatch training loss = {1:.3g} and accuracy of {2:.2g}\"\\\n",
    "                      .format(iter_cnt,loss,np.sum(corr)/actual_batch_size))\n",
    "            iter_cnt += 1\n",
    "        total_correct = correct/Xd.shape[0]\n",
    "        total_loss = np.sum(losses)/Xd.shape[0]\n",
    "        print(\"Epoch {2}, Overall loss = {0:.3g} and accuracy of {1:.3g}\"\\\n",
    "              .format(total_loss,total_correct,e+1))\n",
    "        \n",
    "    if plot_losses:\n",
    "        plt.plot(losses)\n",
    "        plt.grid(True)\n",
    "        plt.title('Epoch {} Loss'.format(e+1))\n",
    "        plt.xlabel('minibatch number')\n",
    "        plt.ylabel('minibatch loss')\n",
    "        plt.show()\n",
    "            \n",
    "    return total_loss,total_correct,losses\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with 1000 training data entries 10 epoch, validate with 50 data entries and test with 100 data entries:\n",
    "\n",
    "Validation\n",
    "\n",
    "Epoch 1, Overall loss = 0.247 and accuracy of 0.94\n",
    "\n",
    "Test\n",
    "\n",
    "Epoch 1, Overall loss = 0.298 and accuracy of 0.89\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "## add filter and train again (with maybe 500 data entries for training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTPTNRate(l,p):#label, predictions\n",
    "    tn, fp, fn, tp = confusion_matrix(l, p).ravel()\n",
    "    tpr = float(tp)/(float(tp) + float(fn))\n",
    "    tnr=float(tn)/(float(tn) + float(fp))\n",
    "    return tpr,tnr\n",
    "\n",
    "\n",
    "def run_model_TF(session, predict, loss_val, Xd, yd,\n",
    "              epochs=1, batch_size=64, print_every=100,\n",
    "              training=None, plot_losses=False):\n",
    "    \n",
    "    # have tensorflow compute accuracy\n",
    "    predictions=tf.argmax(predict,1)\n",
    "    correct_prediction = tf.equal(predictions, y)#array of true and false\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    \n",
    "    actuals=y\n",
    "    ones_like_actuals = tf.ones_like(actuals)#all elements set to 1\n",
    "    zeros_like_actuals = tf.zeros_like(actuals) #all elements set to 0\n",
    "    ones_like_predictions = tf.ones_like(predictions) #all elements set to 1\n",
    "    zeros_like_predictions = tf.zeros_like(predictions) #all elements set to 0\n",
    "    \n",
    "    tp_op = tf.count_nonzero(predictions * actuals)\n",
    "    tn_op = tf.count_nonzero((predictions - 1) * (actuals - 1))\n",
    "    fp_op = tf.count_nonzero(predictions * (actuals - 1))\n",
    "    fn_op = tf.count_nonzero((predictions - 1) * actuals)\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "    \n",
    "    train_indicies = np.arange(Xd.shape[0])\n",
    "    \n",
    "    training_now = (training is not None)\n",
    "    \n",
    "    # setting up variables we want to compute (and optimizing)\n",
    "    # if we have a training function, add that to things we compute\n",
    "    variables = [mean_loss, tp_op, tn_op, fp_op, fn_op, correct_prediction,accuracy]\n",
    "    if training_now:\n",
    "        variables[-1] = training\n",
    "\n",
    "    # counter \n",
    "    iter_cnt = 0\n",
    "    # keep track of losses\n",
    "    losses = []\n",
    "#     tprs=[]\n",
    "    tnrs=[]\n",
    "\n",
    "    for e in range(epochs):\n",
    "        # shuffle indicies\n",
    "        np.random.shuffle(train_indicies)\n",
    "        total_tp=0\n",
    "        total_tn=0\n",
    "        total_fp=0\n",
    "        total_fn=0\n",
    "        correct = 0\n",
    "\n",
    "        # make sure we iterate over the dataset once\n",
    "        for i in range(int(math.ceil(Xd.shape[0]/batch_size))):\n",
    "            # generate indicies for the batch\n",
    "            start_idx = (i*batch_size)%Xd.shape[0]\n",
    "            idx = train_indicies[start_idx:start_idx+batch_size]\n",
    "            \n",
    "            # create a feed dictionary for this batch\n",
    "            feed_dict = {X: Xd[idx,:],\n",
    "                         y: yd[idx],\n",
    "                         is_training: training_now }\n",
    "            # get batch size\n",
    "            actual_batch_size = yd[idx].shape[0]\n",
    "            \n",
    "            # have tensorflow compute loss and correct predictions\n",
    "            # and (if given) perform a training step\n",
    "            loss, tp, tn, fp, fn, corr,_= session.run(variables,feed_dict=feed_dict) #last variable will be automatically be None \n",
    "\n",
    "\n",
    "#             if fn is None:\n",
    "#                 fn=actual_batch_size-tp-tn-fp\n",
    "   \n",
    "            print(tp,tn,fp,fn)\n",
    "            total_tp+=tp\n",
    "            total_tn+=tn\n",
    "            total_fp+=fp \n",
    "            total_fn+=fn\n",
    "            tpr = float(tp)/(float(tp) + float(fn))\n",
    "#             fpr = float(fp)/(float(tp) + float(fn))\n",
    "            tnr=float(tn)/(float(tn) + float(fp))\n",
    "#             accuracy = (float(tp) + float(tn))/(float(tp) + float(fp) + float(fn) + float(tn))\n",
    "            \n",
    "#             recall = tpr\n",
    "#             precision = float(tp)/(float(tp) + float(fp))\n",
    "#             f1_score = (2.0 * (precision * recall)) / (precision + recall)\n",
    "            \n",
    "            # aggregate performance stats\n",
    "            losses.append(loss*actual_batch_size)\n",
    "#             tprs.append(tpr)\n",
    "#             tnrs.append(tnr)\n",
    "#             print(len(tprs),tprs)\n",
    "#             print(len(tnrs),tnrs)\n",
    "#             print(corr)\n",
    "            corr = np.array(corr).astype(np.float32)\n",
    "            \n",
    "            correct += np.sum(corr)\n",
    "\n",
    "            \n",
    "            # print every now and then\n",
    "            if training_now and (iter_cnt % print_every) == 0:\n",
    "                print(\"Iteration {0}: with minibatch training loss = {1:.3g},tpr of {2:.2g},tnr of {3:.2g} and accuracy of {4:.2g}\"\\\n",
    "                      .format(iter_cnt,loss,tpr,tnr,np.sum(corr)/actual_batch_size))\n",
    "            iter_cnt += 1\n",
    "        total_tpr = total_tp/(total_tp+total_fn)\n",
    "        total_tnr=total_tn/(total_tn+total_fp)\n",
    "        total_loss = np.sum(losses)/Xd.shape[0]\n",
    "        total_correct = correct/Xd.shape[0]\n",
    "        \n",
    "\n",
    "\n",
    "        print(\"Epoch {0}, Overall loss = {1:.3g} tpr of {2:.3g},tnr of {3:.3g} and accuracy of {4:.3g}\"\\\n",
    "              .format(e+1,total_loss,total_tpr,total_tnr,total_correct))\n",
    "    \n",
    "        \n",
    "    if plot_losses:\n",
    "        plt.plot(losses)\n",
    "        plt.grid(True)\n",
    "        plt.title('Epoch {} Loss'.format(e+1))\n",
    "        plt.xlabel('minibatch number')\n",
    "        plt.ylabel('minibatch loss')\n",
    "        plt.show()\n",
    "            \n",
    "    return total_loss,total_tpr,total_tnr,losses\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 227, 227])\n",
    "y = tf.placeholder(tf.int64, [None])\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "y_out = cnn_model_fn(X,y,is_training)\n",
    "total_loss = tf.losses.softmax_cross_entropy(logits=y_out, onehot_labels=tf.one_hot(y,2))\n",
    "mean_loss = tf.reduce_mean(total_loss)\n",
    "optimizer = tf.train.AdamOptimizer(1e-4) #adam\n",
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(extra_update_ops):\n",
    "    train_step = optimizer.minimize(mean_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read the data\n",
    "#train 500 negatives and 500 positives\n",
    "#use 50 negatives and 50 positives to validate\n",
    "#100 negatives and 100 positives to test\n",
    "X_train=[]\n",
    "Y_train=[]\n",
    "X_test=[]\n",
    "Y_test=[] \n",
    "X_val=[]\n",
    "Y_val=[]  \n",
    "for i in range(1,501):\n",
    "    j  = i + 1600\n",
    "    txt = '../Negative/0'+str(j).zfill(4)+'.jpg'\n",
    "    img = cv2.imread(txt, 0).astype(np.float32)\n",
    "    X_train.append(img)\n",
    "    Y_train.append(0)\n",
    "    \n",
    "for i in range(1,501):\n",
    "    j  = i + 1600\n",
    "    txt = '../Positive/0'+str(j).zfill(4)+'.jpg'\n",
    "    img = cv2.imread(txt, 0).astype(np.float32)\n",
    "    X_train.append(img)\n",
    "    Y_train.append(1)\n",
    "\n",
    "\n",
    "    \n",
    "for i in range(1,41):\n",
    "    txt = '../Negative/1'+str(i).zfill(4)+'.jpg'\n",
    "    img = cv2.imread(txt, 0).astype(np.float32)\n",
    "    X_val.append(img)\n",
    "    Y_val.append(0)\n",
    "    j  = i + 500\n",
    "    txt = '../Positive/1'+str(i).zfill(4)+'_1.jpg'\n",
    "    img = cv2.imread(txt, 0).astype(np.float32)\n",
    "    X_val.append(img)\n",
    "    Y_val.append(1)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(1,101):\n",
    "    txt = '../Negative/1'+str(j).zfill(4)+'.jpg'\n",
    "    img = cv2.imread(txt, 0).astype(np.float32)\n",
    "    X_test.append(img)\n",
    "    Y_test.append(0)\n",
    "    j  = i + 1000\n",
    "    txt = '../Positive/1'+str(j).zfill(4)+'_1.jpg'\n",
    "    img = cv2.imread(txt, 0).astype(np.float32)\n",
    "    X_test.append(img)\n",
    "    Y_test.append(1)\n",
    "\n",
    "\n",
    "\n",
    "X_test=np.asarray(X_test)\n",
    "Y_test=np.asarray(Y_test)    \n",
    "X_val=np.asarray(X_val)\n",
    "Y_val=np.asarray(Y_val)\n",
    "X_train=np.asarray(X_train)\n",
    "Y_train=np.asarray(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "17 26 9 12\n",
      "Iteration 0: with minibatch training loss = 0.822,tpr of 0.59,tnr of 0.74 and accuracy of 0.67\n",
      "16 23 12 13\n",
      "27 30 3 4\n",
      "22 27 4 11\n",
      "21 33 4 6\n",
      "29 28 0 7\n",
      "23 37 4 0\n",
      "26 31 0 7\n",
      "31 27 1 5\n",
      "28 31 0 5\n",
      "31 27 2 4\n",
      "22 33 2 7\n",
      "29 27 0 8\n",
      "26 31 2 5\n",
      "29 28 1 6\n",
      "20 17 0 3\n",
      "Epoch 1, Overall loss = 1.12 tpr of 0.794,tnr of 0.912 and accuracy of 0.85\n",
      "28 21 3 12\n",
      "27 33 2 2\n",
      "31 33 0 0\n",
      "29 34 1 0\n",
      "30 32 0 2\n",
      "28 34 1 1\n",
      "31 33 0 0\n",
      "31 29 3 1\n",
      "33 29 0 2\n",
      "30 31 0 3\n",
      "28 35 1 0\n",
      "30 31 0 3\n",
      "33 30 0 1\n",
      "34 29 0 1\n",
      "31 33 0 0\n",
      "18 21 1 0\n",
      "Epoch 2, Overall loss = 1.28 tpr of 0.944,tnr of 0.976 and accuracy of 0.96\n",
      "33 30 0 1\n",
      "37 23 0 4\n",
      "26 38 0 0\n",
      "34 29 0 1\n",
      "28 35 0 1\n",
      "28 35 1 0\n",
      "28 35 0 1\n",
      "25 39 0 0\n",
      "30 34 0 0\n",
      "30 32 0 2\n",
      "33 30 0 1\n",
      "34 30 0 0\n",
      "36 28 0 0\n",
      "31 33 0 0\n",
      "30 33 0 1\n",
      "23 15 0 2\n",
      "Epoch 3, Overall loss = 1.34 tpr of 0.972,tnr of 0.998 and accuracy of 0.98\n",
      "35 29 0 0\n",
      "31 33 0 0\n",
      "36 28 0 0\n",
      "30 34 0 0\n",
      "34 30 0 0\n",
      "31 33 0 0\n",
      "31 33 0 0\n",
      "28 35 1 0\n",
      "29 34 1 0\n",
      "33 31 0 0\n",
      "30 34 0 0\n",
      "34 30 0 0\n",
      "33 31 0 0\n",
      "34 30 0 0\n",
      "33 31 0 0\n",
      "18 22 0 0\n",
      "Epoch 4, Overall loss = 1.35 tpr of 1,tnr of 0.996 and accuracy of 1\n",
      "35 28 0 1\n",
      "31 33 0 0\n",
      "31 33 0 0\n",
      "29 35 0 0\n",
      "33 31 0 0\n",
      "32 32 0 0\n",
      "31 33 0 0\n",
      "33 31 0 0\n",
      "25 39 0 0\n",
      "36 28 0 0\n",
      "31 33 0 0\n",
      "29 34 0 1\n",
      "40 24 0 0\n",
      "33 31 0 0\n",
      "32 32 0 0\n",
      "17 22 1 0\n",
      "Epoch 5, Overall loss = 1.36 tpr of 0.996,tnr of 0.998 and accuracy of 1\n",
      "41 23 0 0\n",
      "31 33 0 0\n",
      "34 30 0 0\n",
      "28 35 1 0\n",
      "34 29 0 1\n",
      "29 35 0 0\n",
      "29 35 0 0\n",
      "27 37 0 0\n",
      "37 27 0 0\n",
      "27 37 0 0\n",
      "28 36 0 0\n",
      "36 28 0 0\n",
      "27 37 0 0\n",
      "40 24 0 0\n",
      "32 31 0 1\n",
      "18 22 0 0\n",
      "Epoch 6, Overall loss = 1.38 tpr of 0.996,tnr of 0.998 and accuracy of 1\n",
      "40 24 0 0\n",
      "35 29 0 0\n",
      "29 35 0 0\n",
      "39 24 0 1\n",
      "31 33 0 0\n",
      "Iteration 100: with minibatch training loss = 0.00381,tpr of 1,tnr of 1 and accuracy of 1\n",
      "27 37 0 0\n",
      "39 25 0 0\n",
      "29 35 0 0\n",
      "33 31 0 0\n",
      "26 38 0 0\n",
      "35 29 0 0\n",
      "30 34 0 0\n",
      "32 32 0 0\n",
      "27 37 0 0\n",
      "30 34 0 0\n",
      "17 23 0 0\n",
      "Epoch 7, Overall loss = 1.38 tpr of 0.998,tnr of 1 and accuracy of 1\n",
      "29 35 0 0\n",
      "29 35 0 0\n",
      "33 31 0 0\n",
      "33 31 0 0\n",
      "35 29 0 0\n",
      "35 29 0 0\n",
      "29 35 0 0\n",
      "24 40 0 0\n",
      "31 33 0 0\n",
      "32 32 0 0\n",
      "32 31 0 1\n",
      "34 30 0 0\n",
      "32 32 0 0\n",
      "35 29 0 0\n",
      "34 30 0 0\n",
      "22 18 0 0\n",
      "Epoch 8, Overall loss = 1.39 tpr of 0.998,tnr of 1 and accuracy of 1\n",
      "23 41 0 0\n",
      "34 30 0 0\n",
      "31 33 0 0\n",
      "37 27 0 0\n",
      "34 30 0 0\n",
      "33 31 0 0\n",
      "32 31 1 0\n",
      "33 31 0 0\n",
      "30 34 0 0\n",
      "34 30 0 0\n",
      "40 24 0 0\n",
      "32 32 0 0\n",
      "36 28 0 0\n",
      "28 36 0 0\n",
      "28 36 0 0\n",
      "15 25 0 0\n",
      "Epoch 9, Overall loss = 1.39 tpr of 1,tnr of 0.998 and accuracy of 1\n",
      "29 35 0 0\n",
      "38 26 0 0\n",
      "39 25 0 0\n",
      "29 35 0 0\n",
      "37 27 0 0\n",
      "30 34 0 0\n",
      "22 42 0 0\n",
      "34 30 0 0\n",
      "28 36 0 0\n",
      "30 34 0 0\n",
      "33 30 0 1\n",
      "36 28 0 0\n",
      "29 35 0 0\n",
      "31 33 0 0\n",
      "30 34 0 0\n",
      "24 16 0 0\n",
      "Epoch 10, Overall loss = 1.4 tpr of 0.998,tnr of 1 and accuracy of 1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAAHwCAYAAADjOch3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAIABJREFUeJzs3XmcXGWZ//3vVVW9L+msTRKyAWGX\nzQABXII64I7jgqKj6DCiM+Nv9BnHbX4zjzrjo+iM4zij6DCig4og7ogMiEijIGvAsCaQBLKQkLU7\n6b266lzPH+dUdfVaJ8vpLro/79erX9V1qrrqvrs7yTf3dS/m7gIAAEBlSE12AwAAADCIcAYAAFBB\nCGcAAAAVhHAGAABQQQhnAAAAFYRwBgAAUEEIZwCmNDNzMztmstsBAHERzgBMGDN71sx6zayr5ONr\nk92uAjM72cxuNbPdZjZiE0gzm2VmPzOzbjPbZGbvHOe1PmNm30+2xQCmosxkNwDAtPMGd//NZDdi\nDAOSbpB0paSfj/L41yVlJbVKOk3Sr8xsjbs/PnFNBDDVMXIGoCKY2XvN7G4z+08z22dma83slSWP\nLzCzG81sr5mtN7P3lzyWNrO/N7MNZtZpZqvNbFHJy7/KzJ42s3Yz+7qZ2WhtcPd17n61pBFhy8wa\nJL1F0j+6e5e73yXpRknvPoi+nmBmbWbWYWaPm9kbSx57rZk9EfXjOTP7u+j6HDO7KfqavWb2ezPj\n73BgCmLkDEAlOVvSjyXNkfRmST81s2XuvlfSdQpD0wJJx0u6zcw2uvvtkv5W0iWSXivpKUmnSOop\ned3XSzpTUrOk1ZJ+KemWA2zbsZLy7v5UybU1kl5+IC9iZlXR+39b0gWSXiLpF2a2wt3XSbpa0sXu\n/nszmylpWfSlH5W0VdLc6P5KSZy/B0xB/K8LwET7eTT6U/h4f8ljOyX9u7sPuPsPJa2T9LpoFOwl\nkj7h7n3u/kdJ39LgqNVfSPqHaOTL3X2Nu+8ped0r3L3D3TdLukNhSfJANUraN+zaPklNB/g6K6PX\nusLds+7+W0k3KQyXUlhaPdHMmt293d0fKrk+X9KS6Pvze+dwZGBKIpwBmGhvcveWko//LnnsuWGB\nY5PCkbIFkva6e+ewxxZGny+StGGc93y+5PMeheHoQHUpHHkr1Sypc5TnjmeBpC3uHpRcK+3LWxSO\nAG4yszvN7Jzo+r9IWi/p12a20cw+eYDvC+AFgnAGoJIsHDYfbLGkbdHHLDNrGvbYc9HnWyQdnXDb\nnpKUMbPlJddO1Sjz08rYJmnRsPlixb64+wPufpGkeQoXJdwQXe9094+6+1GS3iDpb0vn5AGYOghn\nACrJPEl/Y2ZVZvY2SSdIutndt0j6g6QvmFmtmZ0i6TJJ10Zf9y1J/2xmyy10ipnNPtA3j762VlJ1\ndL/WzGokyd27Jf1U0j+ZWYOZnSfpIknfG+clU9Fr1Ja81n2SuiV9POrnKoVh63ozqzazd5nZDHcf\nkLRfUj5qy+vN7JgovBau5w+0jwAqH+EMwET75bB9zn5W8th9kpZL2i3p/5P01pK5Y5dIWqpw5Oln\nkj7t7rdFj/2bwhGmXysMLldLqjuIti2R1KvB0bBehfPeCv4qet2dChco/GWZbTQuiV6j8LHB3bOS\n3ijpNVE/r5T0HndfG33NuyU9a2b7JX1Q0p9F15dL+o3C8uo9kq5097aD6COACmfMJwVQCczsvZL+\nwt1fMtltAYDJxMgZAABABSGcAQAAVBDKmgAAABWEkTMAAIAKQjgDAACoIC/oszXnzJnjS5cuTfQ9\nuru71dDQkOh7VDL6T//p//Ts/3Tuu0T/6X8y/V+9evVud59b7nkv6HC2dOlSPfjgg4m+R1tbm1at\nWpXoe1Qy+k//6f+qyW7GpJjOfZfoP/1Ppv9mtinO8yhrAgAAVBDCGQAAQAUhnAEAAFQQwhkAAEAF\nIZwBAABUEMIZAABABUk0nJnZs2b2qJn90cwejK7NMrPbzOzp6HZmdN3M7D/MbL2ZPWJmZyTZNgAA\ngEo0ESNn57v7ae6+Irr/SUm3u/tySbdH9yXpNZKWRx+XS/rGBLQNAACgokxGWfMiSddEn18j6U0l\n17/roXsltZjZ/EloHwAAwKQxd0/uxc2ekdQuySX9l7tfZWYd7t5S8px2d59pZjdJusLd74qu3y7p\nE+7+4LDXvFzhyJpaW1tffP311yfWfknq6upSY2Njou9Ryeg//af/07P/07nvEv2n/8n0//zzz19d\nUkkcU9LHN53n7tvMbJ6k28xs7TjPtVGujUiO7n6VpKskacWKFZ708RIcYUH/6f+qyW7GpJnO/Z/O\nfZfoP/2f3P4nWtZ0923R7U5JP5N0lqQdhXJldLszevpWSYtKvvxISduSbB8AAEClSSycmVmDmTUV\nPpd0gaTHJN0o6dLoaZdK+kX0+Y2S3hOt2lwpaZ+7b0+qfQAAAJUoybJmq6SfmVnhfX7g7reY2QOS\nbjCzyyRtlvS26Pk3S3qtpPWSeiS9L8G2AQAAVKTEwpm7b5R06ijX90h65SjXXdJfJ9UeAACAFwJO\nCAAAAKgghDMAAIAKQjiLqbNvQCs+d5vu3bhnspsCAACmMMJZTO3dA9rdldXmPT2T3RQAADCFEc5i\nCqKTFPIJnqgAAABAOIupEM4CwhkAAEgQ4SymwIfeAgAAJIFwFlNx5Ix0BgAAEkQ4i4myJgAAmAiE\ns5iCILolmwEAgAQRzmIqjJg5I2cAACBBhLOYiltpMHQGAAASRDiLidWaAABgIhDOYiqMmLEgAAAA\nJIlwFpMz5wwAAEwAwllMhXJmPpjcdgAAgKmNcBYTZU0AADARCGcxUdYEAAATgXAWE6s1AQDARCCc\nxZQv7HPGyBkAAEgQ4SwmztYEAAATgXAW0+Ccs0luCAAAmNIIZzEVttAImHQGAAASRDiLKWDOGQAA\nmACEs5goawIAgIlAOItpcCsN0hkAAEgO4SymwgkBeeacAQCABBHOYhrcSmOSGwIAAKY0wllMhWom\nxzcBAIAkEc5i4uBzAAAwEQhnMRW30ggmuSEAAGBKI5zFRFkTAABMBMJZTHnO1gQAABOAcBYTqzUB\nAMBEIJzFVAhlHN8EAACSRDiLqXDgOXPOAABAkghnMRXLmqzWBAAACSKcxcTZmgAAYCIQzmIK2IQW\nAABMAMJZTKzWBAAAE4FwFhNlTQAAMBEIZzExcgYAACYC4Sym4pwz0hkAAEgQ4SwmypoAAGAiEM5i\nCjhbEwAATADCWUzMOQMAABOBcBbT4AkBpDMAAJAcwllMzDkDAAATgXAW0+AJAZPcEAAAMKURzmJi\nQQAAAJgIhLOYKGsCAICJQDiLKV/chHaSGwIAAKY0wllMTlkTAABMAMJZTJQ1AQDARCCcxZRnE1oA\nADABCGcxUdYEAAATgXAWU2EhANkMAAAkiXAWU2HELE9dEwAAJIhwFlOesiYAAJgAhLOYCpmMbAYA\nAJJEOIuJ45sAAMBEIJzFVJhrxpwzAACQJMJZTF7chHZy2wEAAKY2wllMhXKmU9YEAAAJIpzFVDz4\nnHAGAAASRDiLqVDOZM4ZAABIEuEsJi+WNSe5IQAAYEojnMXEJrQAAGAiEM5iClitCQAAJgDhLKZC\nWTPPyBkAAEgQ4SymwkIAttIAAABJSjycmVnazB42s5ui+8vM7D4ze9rMfmhm1dH1muj++ujxpUm3\n7UAMHt80yQ0BAABT2kSMnH1Y0pMl978o6SvuvlxSu6TLouuXSWp392MkfSV6XsVgKw0AADAREg1n\nZnakpNdJ+lZ03yS9QtKPo6dcI+lN0ecXRfcVPf7K6PkVobScSWkTAAAkJemRs3+X9HFJQXR/tqQO\nd89F97dKWhh9vlDSFkmKHt8XPb8ilI6YMXgGAACSkknqhc3s9ZJ2uvtqM1tVuDzKUz3GY6Wve7mk\nyyWptbVVbW1th97YcXR1damtrU0d+3qL1+5oa1MmVTGDeokq9H+6ov/0f7r2fzr3XaL/9H9y+59Y\nOJN0nqQ3mtlrJdVKalY4ktZiZplodOxISdui52+VtEjSVjPLSJohae/wF3X3qyRdJUkrVqzwVatW\nJdgFqa2tTatWrdJXHrtL2rdPkvSSl75MtVXpRN+3UhT6P13Rf/o/Xfs/nfsu0X/6P7n9T6ys6e6f\ncvcj3X2ppHdI+q27v0vSHZLeGj3tUkm/iD6/Mbqv6PHfegVN7soPmXM2iQ0BAABT2mTsc/YJSX9r\nZusVzim7Orp+taTZ0fW/lfTJSWjbmIKg5HPSGQAASEiSZc0id2+T1BZ9vlHSWaM8p0/S2yaiPQej\nNJARzgAAQFI4ISCmIeEsGOeJAAAAh4BwFlPp9hmMnAEAgKQQzmKirAkAACYC4SymgE1oAQDABCCc\nxURZEwAATATCWUyUNQEAwEQgnMVEWRMAAEwEwllMgUvp6DzNgHQGAAASQjiLKXAvHnZOWRMAACSF\ncBZT4CoJZ5PcGAAAMGURzmIK3AfLmoycAQCAhBDOYgrcVZUOv13MOQMAAEkhnMUUBK5MmrImAABI\nFuEspnDOWTRyRlkTAAAkhHAWU+ClI2eEMwAAkAzCWUxDFgQEk9wYAAAwZRHOYgoCqYqyJgAASBjh\nLCbKmgAAYCIQzmIaekLAJDcGAABMWYSzGNw9XK2ZpqwJAACSRTiLoZDFOPgcAAAkjXAWQ2GkrIpN\naAEAQMIIZzHko3CWjlZrOmVNAACQEMJZDIUsVhWVNfOEMwAAkBDCWQyFsiZnawIAgKQRzmIohDHO\n1gQAAEkjnMWQD4aOnDHnDAAAJIVwFkMhjBVGzvKcrQkAABJCOIthsKzJ8U0AACBZhLMYCmXNNGVN\nAACQMMJZDIUwVsXZmgAAIGGEsxiKZc10Yc4Z6QwAACSDcBZDvrgggDlnAAAgWYSzGIIRW2lMZmsA\nAMBURjiLoRDG0inKmgAAIFmEsxjyIxYEEM4AAEAyCGcxFMJYmrImAABIGOEshsGtNDhbEwAAJItw\nFkPhuKZ0VNbME84AAEBCCGcxFEbKqtJsQgsAAJJFOIuhEM4Km9ByfBMAAEgK4SyGYFhZM2DoDAAA\nJIRwFsPwsmaebAYAABJCOIuhWNZMUdYEAADJIpzFUDz4nE1oAQBAwghnMQxfEMCUMwAAkBTCWQzD\nDz7nbE0AAJAUwlkMw8uazDkDAABJIZzFUDxbM8UmtAAAIFmEsxgGt9LgbE0AAJAswlkMhZGylJnM\n2IQWAAAkh3AWQyGMpSwMaGQzAACQFMJZDKVzzlJGWRMAACSHcBbD0LImI2cAACA5hLMYCvuamUlp\nM0bOAABAYghnMRT2NUtZVNZk6AwAACSEcBZDIYuFc84oawIAgOQQzmLI++BqTWNBAAAASBDhLIZC\nWdPMlE4x5wwAACSHcBZDcSsNK5Q1CWcAACAZhLMYgiC8ZSsNAACQNMJZDHkf3EqD1ZoAACBJhLMY\nvOSEAOacAQCAJBHOYig9IYCtNAAAQJIIZzHkA7bSAAAAE4NwFkPxhIBCWZOhMwAAkBDCWQyUNQEA\nwEQhnMVAWRMAAEwUwlkMQUlZM2UmshkAAEgK4SwGLylrps2KI2kAAACHG+EsBg4+BwAAE4VwFkOx\nrMmCAAAAkLDEwpmZ1ZrZ/Wa2xsweN7PPRteXmdl9Zva0mf3QzKqj6zXR/fXR40uTatuBKi1rplKD\nW2sAAAAcbkmOnPVLeoW7nyrpNEmvNrOVkr4o6SvuvlxSu6TLoudfJqnd3Y+R9JXoeRWhdLVm2qxY\n5gQAADjcEgtnHuqK7lZFHy7pFZJ+HF2/RtKbos8viu4revyVZmZJte9AlJY1jbImAABIUKJzzsws\nbWZ/lLRT0m2SNkjqcPdc9JStkhZGny+UtEWSosf3SZqdZPviKm5CmzKljLImAABITibJF3f3vKTT\nzKxF0s8knTDa06Lb0UbJRqQgM7tc0uWS1Nraqra2tsPT2DF0dXXpme3PyiS1tbWpc3+velNK/H0r\nRVdX17Tp62joP/2frv2fzn2X6D/9n9z+JxrOCty9w8zaJK2U1GJmmWh07EhJ26KnbZW0SNJWM8tI\nmiFp7yivdZWkqyRpxYoVvmrVqkTb3tbWpkWLjlD6mY1atWqVrlx3j1ImrVp1TqLvWyna2tqU9Pe4\nktF/+j9d+z+d+y7Rf/o/uf1PcrXm3GjETGZWJ+lVkp6UdIekt0ZPu1TSL6LPb4zuK3r8t14h9cPA\nw5KmFC4KYM4ZAABISpIjZ/MlXWNmaYUh8AZ3v8nMnpB0vZl9TtLDkq6Onn+1pO+Z2XqFI2bvSLBt\nB8TdFWUzpcyUD4LJbRAAAJiyEgtn7v6IpNNHub5R0lmjXO+T9Lak2nMo8oErZYWRM45vAgAAyeGE\ngBgCD/c3k8LyJtkMAAAkhXAWQ+AuK5Y12UoDAAAkh3AWQ+BesiCAkTMAAJAcwlkMgftgWdPEnDMA\nAJAYwlkMgUtmpSNnhDMAAJCMsuHMzD5sZs0WutrMHjKzCyaicZUiCIZupUE2AwAASYkzcvbn7r5f\n0gWS5kp6n6QrEm1VhQm8ZCuNlBg5AwAAiYkTzgpnXr5W0nfcfY1GPwdzygpcSpcsCMgTzgAAQELi\nhLPVZvZrheHsVjNrkjSttsgPgtKtNChrAgCA5MQ5IeAySadJ2ujuPWY2S2Fpc9oYUtY0ypoAACA5\ncUbOzpG0zt07zOzPJP2DpH3JNquyDC9rEs4AAEBS4oSzb0jqMbNTJX1c0iZJ3020VRVmyAkBKRPn\nngMAgKTECWc5D88rukjSV939q5Kakm1WZaGsCQAAJkqcOWedZvYpSe+W9FIzS0uqSrZZlSUISg4+\np6wJAAASFGfk7O2S+hXud/a8pIWS/iXRVlWY0rKmcbYmAABIUNlwFgWyayXNMLPXS+pz92k356xQ\n1kynwq01AAAAkhDn+KaLJd0v6W2SLpZ0n5m9NemGVRJWawIAgIkSZ87Z/5V0prvvlCQzmyvpN5J+\nnGTDKkk4chZ+nqKsCQAAEhRnzlmqEMwie2J+3ZSRD1wWlTXNKGsCAIDkxBk5u8XMbpV0XXT/7ZJu\nTq5JlcdLypppypoAACBBZcOZu3/MzN4i6TyFB55f5e4/S7xlFWRIWTNFWRMAACQnzsiZ3P0nkn6S\ncFsq1oiyJiNnAAAgIWOGMzPrlDRaCjFJ7u7NibWqwjirNQEAwAQZM5y5+7Q6omk8gbuqhsw5m+QG\nAQCAKWtarbo8WHnO1gQAABOEcBZD4CqZc2Zyl5yABgAAEkA4i8HdlS7ZhFYSpU0AAJAIwlkMw8/W\nLFwDAAA43OKcrflmM3vazPaZ2X4z6zSz/RPRuEqRD4aWNSXCGQAASEacfc6+JOkN7v5k0o2pVO5e\nHDErjKCRzQAAQBLilDV3TOdgJo1e1swz6QwAACRgvE1o3xx9+qCZ/VDSzyX1Fx53958m3LaKkQ9K\nt9KgrAkAAJIzXlnzDSWf90i6oOS+S5o24cw9PFNTKp1zNpktAgAAU9V4JwS8byIbUsmGHHwe3bLP\nGQAASEKc1ZrXmFlLyf2ZZvbtZJtVWfJD5pyFt8w5AwAASYizIOAUd+8o3HH3dkmnJ9ekyhMEg3PN\nKGsCAIAkxQlnKTObWbhjZrMUbwuOKcMpawIAgAkSJ2R9WdIfzOzHChcCXCzp84m2qsIMPfickTMA\nAJCcsuHM3b9rZg9KeoUkk/Rmd38i8ZZVkKBktWY6Cmd5Rs4AAEACyoYzM/ueu79b0hOjXJsWSsua\nUTZTwNAZAABIQJw5ZyeV3jGztKQXJ9OcyjTaJrQMnAEAgCSMGc7M7FNm1inplJIDzzsl7ZT0iwlr\nYQUIfHAhQKpwfBPpDAAAJGDMcObuX3D3Jkn/4u7N7t4Ufcx2909NYBsnXeBenHPG8U0AACBJcRYE\nfCraSmO5pNqS679LsmGVJBi1rEk4AwAAh1+cBQF/IenDko6U9EdJKyXdo3D15rQwpKzJVhoAACBB\ncRYEfFjSmZI2ufv5Ck8H2JVoqyrM0LJmeI3jmwAAQBLihLM+d++TJDOrcfe1ko5LtlmVxX1wxKwQ\n0phzBgAAkhDnhICt0cHnP5d0m5m1S9qWbLMqS37I8U1spQEAAJITZ0HAn0affsbM7pA0Q9Itibaq\nwgTuxZMBCiGNkTMAAJCEWAeYm9kZkl6i8GzNu909m2irKoi7y12yYas1mXMGAACSUHbOmZn9v5Ku\nkTRb0hxJ3zGzf0i6YZWiEMFGzjmbpAYBAIApLc7I2SWSTi9ZFHCFpIckfS7JhlWKQghLRzG2UNZk\nnzMAAJCEOKs1n1XJ5rOSaiRtSKQ1FagQwYaXNRk5AwAASRhz5MzM/lNhNumX9LiZ3Rbd/xNJd01M\n8yZfIYQNPyGAOWcAACAJ45U1H4xuV0v6Wcn1tsRaU4GcsiYAAJhAY4Yzd79mIhtSqVgQAAAAJtJ4\nZc0b3P1iM3tUgxmlyN1PSbRlFaIQwox9zgAAwAQYr6z54ej29RPRkErlxTlnhdtozhnhDAAAJGC8\nsub26HbTxDWn8gTRbTo1dEEAc84AAEAS4mxC+2Yze9rM9pnZfjPrNLP9E9G4SlAoX47YSiMY80sA\nAAAOWpxNaL8k6Q3u/mTSjalEw8uaUTajrAkAABIRZxPaHdM1mEmDKyEKB58XypuUNQEAQBLijJw9\naGY/lPRzhRvSSpLc/aeJtaqC+Bib0LKVBgAASEKccNYsqUfSBSXXXNK0CGeDW2mEt2ylAQAAklQ2\nnLn7+yaiIZWqWNaMUplxfBMAAEjQeJvQftzdv1RyxuYQ7v43ibasQgw/W3NwztlktQgAAExl442c\nFRYBPDjOc6Y8ypoAAGAijbcJ7S+j22l9xubwsiYLAgAAQJLKzjkzsxWS/q+kJaXPny5naw5frVkY\nQQtIZwAAIAFxVmteK+ljkh7V4GlG00ahfFkoZxZG0ChrAgCAJMQJZ7vc/cbEW1KhChGMfc4AAMBE\niBPOPm1m35J0u9iEdrCsycgZAABIQJxw9j5Jx0uq0mBZs+wmtGa2SNJ3JR0Rfd1V7v5VM5sl6YeS\nlkp6VtLF7t5u4QZiX5X0WoWb3r7X3R860A4dbsWtNKKDrtJGWRMAACQnTjg71d1fdBCvnZP0UXd/\nyMyaJK02s9skvVfS7e5+hZl9UtInJX1C0mskLY8+zpb0jeh2UhXSqA0va1LXBAAACYhz8Pm9Znbi\ngb6wu28vjHy5e6fCfdMWSrpIUmF7jmskvSn6/CJJ3/XQvZJazGz+gb7v4VYYIEsz5wwAAEyAOCNn\nL5F0qZk9o3DOmUnyA9lKw8yWSjpd0n2SWt19u8IX2W5m86KnLZS0peTLtkbXtsd9nyQMPyHAUoXr\npDMAAHD4xQlnrz6UNzCzRkk/kfQRd99fKA+O9tRRro1IQGZ2uaTLJam1tVVtbW2H0ryyenp7JZke\neWSNcs+l1ZcLm/T0+g1qy29O9L0rQVdXV+Lf40pG/+n/dO3/dO67RP/p/+T2P87B55sO9sXNrEph\nMLu2ZHXnDjObH42azZe0M7q+VdKiki8/UtK2UdpzlaSrJGnFihW+atWqg21eLE/+5HZJfTrj9NO0\n8qjZ6s3mpd/comVHHaVVLz860feuBG1tbUr6e1zJ6D/9n679n859l+g//Z/c/seZc3ZQotWXV0t6\n0t3/reShGyVdGn1+qaRflFx/j4VWStpXKH9OpuH7nLGVBgAASFKcsubBOk/SuyU9amZ/jK79vaQr\nJN1gZpdJ2izpbdFjNyvcRmO9wq003pdg22IbfkJAIaSRzQAAQBISC2fufpdGn0cmSa8c5fku6a+T\nas/BGtznLOxK4fimPMs1AQBAAhIra04VI49vCu9T1gQAAEkgnJUxuJVGeGvscwYAABJEOCtj+Nma\n4eecEAAAAJJBOCtjeFlTCuedUdYEAABJIJyVMfzgcyksbTJwBgAAkkA4K2P42ZpSWNZ0Rs4AAEAC\nCGdlBNGtDQlnxlYaAAAgEYSzMoav1pTCUTSyGQAASALhrIxC+TJdks7M2OcMAAAkg3BWxmirNVMp\nY84ZAABIBOGsjEL5siSbhXPOCGcAACABhLMyRt+EljlnAAAgGYSzMgoZrHTOGVtpAACApBDOyhir\nrBkEoz8fAADgUBDOyghGKWumU8w5AwAAySCclVEsaxpbaQAAgOQRzsoYa0EA2QwAACSBcFZGcc5Z\nyXcqxcgZAABICOGsjNHKmqkUZ2sCAIBkEM7KKGyZQVkTAABMBMJZGaNvpUFZEwAAJINwVkZhO7Oh\nm9Aa4QwAACSCcFbGWKs182xCCwAAEkA4K2NwE9rBa6kUxzcBAIBkEM7KcIXzzWzEweeEMwAAcPgR\nzspwH1rSlMKgliebAQCABBDOygh8aElTktJGWRMAACSDcFZGWNYcms4oawIAgKQQzsoIfOjpAFIU\nzlitCQAAEkA4K8PlI8qaZlKekTMAAJAAwlkZwSgLAtIpY84ZAABIBOGsDPfwoPNS4ZyzSWoQAACY\n0ghnZbhGrtY0ztYEAAAJIZyVMVpZM1wQQDgDAACHH+GsjNHKmukUZU0AAJAMwlkZgUaWNVOUNQEA\nQEIIZ2WMdXwTI2cAACAJhLMyRt1KgzlnAAAgIYSzMlxSath3KZWirAkAAJJBOCsjcB+jrEk4AwAA\nhx/hrAwf42xNshkAAEgC4awMV7jpbKk0Z2sCAICEEM7KGHMTWsIZAABIAOGsjPD4plHmnAWT0x4A\nADC1Ec7KCEY9+JzVmgAAIBmEszLCTWiHXguPbyKcAQCAw49wVkZ4fBMnBAAAgIlBOCtjtIPPUyZ5\nycjZ3u6s9nT1T3TTAADAFEQ4K2O0smbKTPmSobNP/OQR/d2P1kxwywAAwFSUmewGVLpAI08ICOec\nDd7fub9P2Tx1TgAAcOgIZ2WMdkKADVut2ZPNqy+Xn+imAQCAKYhwVkbgI08IGH58U082r55sbmIb\nBgAApiTmnJUx2ia0KdOQOWe9A3l19zNyBgAADh3hrIzAwzlmpVLD9jnryeaUzQfqp7QJAAAOEeGs\nDC9T1gwCV99AeJZTVx+lTQAAcGgIZ2WMtglt6fFNvQODo2WUNgEAwKEinJXho5U1zZSPwll3yUKA\nzv6BCW0bAACYeghnZYQLAoYK5VbBAAAgAElEQVReK5Q13V292cHRMsqaAADgUBHOygi30hg5ciaF\no2o9JeGsm+00AADAISKcleHuIzahLYykBe5DwlknI2cAAOAQEc7KCCSlhn2XCgeh54eXNfsJZwAA\n4NAQzsooX9YcDGTMOQMAAIeKcFaG++hbaUhhWXPoVhqEMwAAcGgIZ2W4pPQoqzWlcFStdG+zTsIZ\nAAA4RISzMkYdOSvMOQu8WNZsqE5T1gQAAIeMcFbG6HPOwtvSfc7mNtWwlQYAADhkhLMyXFJ6+GrN\nkrJmz0BeVWlTS301W2kAAIBDRjgrIxhnQUA+CEfO6qrSaqrNsJUGAAA4ZISzMkYta6YKW2mEc87q\nqzNqqM6wWhMAABwywlkZLh+/rJnNq746rcbaDAsCAADAISOclVF2n7NsXvU1aTXWZNhKAwAAHDLC\nWRmjzTkrlDnzgas7m1N9VUaNNWFZ090no5kAAGCKSCycmdm3zWynmT1Wcm2Wmd1mZk9HtzOj62Zm\n/2Fm683sETM7I6l2HSjXyHCWLjm+qTebV11U1gxcQ04MAAAAOFBJjpz9j6RXD7v2SUm3u/tySbdH\n9yXpNZKWRx+XS/pGgu06IGFZc+i1wkHogfvgnLOajCTO1wQAAIcmsXDm7r+TtHfY5YskXRN9fo2k\nN5Vc/66H7pXUYmbzk2rbgQh8cHVmweCCgDCc1ZWGM+adAQCAQ5CZ4PdrdfftkuTu281sXnR9oaQt\nJc/bGl3bPvwFzOxyhaNram1tVVtbW6INDty1dcsWtbXtKF57cnsYwO69737t7+5Vx64deka7JUl3\n/uE+bZ6RTrRNE6mrqyvx73Elo//0f7r2fzr3XaL/9H9y+z/R4WwsNsq1UWfWu/tVkq6SpBUrVviq\nVasSbJbkt/5KS5cs1qpVxxevdT+yXVrzkFaceaYG7rtLxyxbrHOOn6evPnSvjjvpVJ17zJxE2zSR\n2tralPT3uJLRf/o/Xfs/nfsu0X/6P7n9n+jVmjsK5crodmd0faukRSXPO1LStglu26jGOyEgl3f1\nDQSqqxosa7KdBgAAOBQTHc5ulHRp9Pmlkn5Rcv090arNlZL2Fcqfky1crTn0WmErjZ7ooPPSBQGc\nEgAAAA5FYmVNM7tO0ipJc8xsq6RPS7pC0g1mdpmkzZLeFj39ZkmvlbReUo+k9yXVrgNR2LNs5IKA\n8LYwSlZfk1FjLQsCAADAoUssnLn7JWM89MpRnuuS/jqpthysIJr1NmKfsyidFbbNqC8ta7KVBgAA\nOAScEDCOfJTORuxzFoW1QgmzvjqtmkxKmZRR1gQAAIeEcDaOYIyyZmEgrVDCrKtOy8zCw88JZwAA\n4BAQzsbhZcqa3f3hUU311WFJs7EmwwkBAADgkBDOxpH38cuaXf0DksKyphSFM0bOAADAISCcjaNY\n1rSxyprhyFkd4QwAABwmhLNxeBDejtyEduSCAEnMOQMAAIeMcDaOscqaxa00CuGsKpxz1sDIGQAA\nOESEs3EUyprpMTahLUz+L5Q1m1gQAAAADhHhbByFcGYj5pwNjpxVpU3VmfDbyJwzAABwqAhn4wjK\nzTnL5lRXlS5eb6jJqCebL25eCwAAcKAIZ+MYLGsOvZ62weObCnucSVJTdL5md5bRMwAAcHAIZ+MY\nu6wZ3nb154orNSUVz9dk3hkAADhYhLNxlCtr9ueC4mIAKdxKQxLzzgAAwEEjnI0jGOuEgJLvWunI\nWUMN4QwAABwawtk4xtpKI10yklZXOueMsiYAADhEhLNxFBZdjrWVhiTVV70wypobdnXp1M/+Wlv2\n9kx2UwAAwDgIZ+MYs6xZcr++pqSsWV254Wzd853a1zug9bu6JrspAABgHISzcRTLmmMsCJCGzjkr\nbKVRiWXN9p6sJGl/78AktwQAAIyHcDaOwmrN4WXN0jlopfucVfKCgPbuKJxVYHAEAACDCGfjGKus\nWZrVSk8IqEqnVJNJqbsSw1lPOGLGyBkAAJWNcDaOsQ8+H72sKYWlzc6KDGeFkTPCGQAAlYxwNo7C\nas2xNqGVRoazxppMRc456yiOnFVe2wAAwCDC2TgKB5jbOJvQlu5zJoXzziqzrMnIGQAALwSEs3H4\nQZQ1G2sqs6xZGDnrrMBRPQAAMIhwNo44Zc26UeacVWJZk600AAB4YSCcjWOssmbpvmcNo5Q1K20r\njXzg2heFMsqaAABUNsLZOHyMTWhtjIPPpbCsWWlzzvb3DijqCgsCAACocISzcRTLmuPMORte1myp\nr1JH70Bx1K0S7I1Kmkc01zJyBgBAhSOcjSMf52zNYeFs/ow65QPXrs7+pJsXW0cUzhbPrlc2F6hv\nID/JLQIAAGMhnI1j8ISAcVZrVg2dc7agpVaStG1fb8Kti6+9OxwtWzKrXhLzzgAAqGSEs3F4jHA2\nvKw5f0adJGl7R1/CrYuvsFJzyewonDHvDACAikU4G0fh4POR4Sy8zaRM1Zmh38IFhXB2mEfONu3p\n1srP3651z3ce8NcW9jhbPLtBEiNnAABUMsLZOApzzkacEBBdGD5qJknNdRnVV6e17TCPnN32xA49\nv79P92zYfcBf296TVSZlWhiVXNnrDACAykU4G8fpi1r0f06v0eKoHFhQWL05fDGAJJmZ5s+oPewj\nZ3evD0PZuh1dB/y17T0Daqmv0oy6KknS/grcJBcAAIQIZ+OY11yrF7dm1FxbNeKxlI3cgLZgQUud\ntu07fCNnA/lA9z+zV5L01I6DKWtm1VJfXewHI2cAAFQuwtlBSpmNWtaUFI6cdRy+kbM1WzrUnc1r\n/oxaPfV8Z3GhQlztPVnNrK9SczRyxvmaAABULsLZQUqZjVrWlMIVm7u6+pXNBYflve5av1tm0p+t\nXKLO/py2H+CoXHv3gFrqq1WTSakqbSwIAACgghHODlIqJdWNWdaslbu0Y//hKW3+Yf0evWjhDJ25\ndJYkad0Bljbbe7KaVV8tM1NzbRVlTQAAKhjh7CClzFRfNfbImaQxR7jcXe/9zv26+dHtZd+nuz+n\nh7e069yj5+jY1kZJ0lMHsJ2Gu6ujZ0AtDWFJs7muigUBAABUMMLZQRqvrFk8JWCMeWeb9/aobd0u\n/eaJHWXf5/5n92og7zrvmNlqqa9Wa3PNAY2c9WTzyuYDzayvliQ112YYOQMAoIIRzg5Sykbf50wa\nHDkb6winP27pkCRt2FV+W4w/rN+t6kyqWNI8trXpgFZsFk4HmFlfOnJGOAMAoFIRzg7Sp157gi45\na/GojzXUZNRcmxnzCKc1W/ZJkjbs6i678vLu9Xv04sUzVRuVUI9rbdLTO7qUD+Kt2CycDtBSHDlj\nzhkAAJWMcHaQLjlrsU5eOGPMxxe01I25Ee2areHIWVd/Tjv294/5Gnu6+vXE9v0675jZxWvHHdGk\n/lygTXu6Y7VzcOQsCmd1GeacAQBQwQhnCZk/o3bUI5wG8oEee26fTlrQLGn80uYfNuyRJJ17zJzi\nteOOaJIUfzPa9mjkrFjWZOQMAICKRjhLyPwxRs7WPd+p/lygN59xpKTxw9mtjz+v2Q3VOqVkhO6Y\neY0yk9Y9H+8Yp/bucOSsWNasq1J/LlDfQD52XwAAwMQhnCVkwYxatfcMqDc7NAQVFgP8yQmtaqrJ\naP3O0UNW30Bev127UxeefIQy6cEfU311Rotn1R/AyFkhnIUjZ0214d5snBIAAEBlIpwlZHCvs6Gj\nZ2u2dGhWQ7UWzarTUfMaxxw5a1u3Uz3ZvF73ovkjHju2tSn2dhodPQNqqs2oKgp4xfM1WbEJAEBF\nIpwlZH6019nwjWjXbO3QqUfOkJnpmLmN2rBz9In9v3r0ec1qqNbZy2aNeOy41iY9s7tb/bnypcnw\nXM3q4v3mOkbOAACoZISzhCwo7HVWshFtV39OT+/s0qmLWiRJR89r0PP7+9Q5bBSrbyCv25/coQtP\nGlrSLDj2iCblA9fGXeVXbLb3DBQXA0glI2csCgAAoCIRzhJyxIyRI2ePbt0ndw2Gs7nhcUzDQ1bb\nul1jljQl6fhoxebj2/aXbUdHT7a4GEAKFwRIlDUBAKhUhLOE1FalNbuhesics8JigFOPDMPZMfPC\ncDZ83tnNj27XrIZqrTxqZElTkpbNadD8GbX6zI2P69bHnx+3HWFZc7SRM8qaAABUIsJZgua3DN3r\nbM2WDi2eVa9ZDeFI1uJZ9cqkbEg4Gyxpto5a0pSkqnRKP/7Lc3XU3AZ94Hur9aVb1uqx5/bpyrb1\nevt/3aP/54d/LD63o3tg2MhZOOeMkTMAACpTZrIbMJXNn1E3ZCf/NVs7imdkSmHIWjK7fsh2Gnc+\ntUvd2bxeO0ZJs2BhS51u+MA5+syNj+vKtg26sm2DpHALj/ue2at3nLlIZyyZqc7+3JAFAXVVaWVS\nxpwzAAAqFOEsQQtm1OreDXvU1Z/TDQ9s0fZ9fcX5ZgXHzGvUhmjOmbvr+/du0qyGap1z1OzRXnKI\n2qq0rnjLKXrVCa3q6B3Qy5bPUXNdlV7yxTv0tTvW68sXnypJmtkwWNY0Mw4/BwCgghHOEjS/pU6d\n/Tmd8/nb1dmf02mLWvTGUxcMec7Rcxv127U7NZAPdNfTu/X7p3frH19/4pglzdG86sTWIfcvf9ky\nff7mtWpbt0uShpQ1Jam5NsOcMwAAKhThLEGnLWpRTSal84+fp/edt1SnL5454jlHz23UQN71zO5u\nfe5XT2jZnAa9e+WSQ3rfd529RFe2bdC/3rpOkjRrWDhrqmXkDACASkU4S9DKo2Zr3edeM+5zjo5W\nbP7zTU9ow65u/fd7Vqg6c2jrNBpqMrrsvGX68m1PSRo8uqmguS7DnDMAACoUqzUn2dFzGyRJv396\nt849erZedcK8w/K67zl3qZpqwuw9s2F4WbNK+zkhAACAikQ4m2RNtVVqba5RyqR/fP2JMrPD8roz\n6qr05y9ZpvrqcL+1Us21VYycAQBQoShrVoCLVyxSJpXSCfObD+vrfviVy/WulYtVW5Uecr25LsOc\nMwAAKhThrAJ89ILjEnndVMo0r6l2xPXm2ir1DQTK5oJDnt8GAAAOL/5lnoYK52sOP3AdAABMPsLZ\nNDR4hNPkLArY1dmvV//777R6095JeX8AACoZ4WwaGjz8fHJGzm55/Hmtfb5Tn/vVk3L3SWkDAACV\ninA2DRXKmpO1KOA3T+xQOmV6eHOHfrt256S0AQCASkU4m4aaaqOyZsJHOHX0ZPXUjs4h17r6c7pn\nwx69e+USLZldr3/99VMKAkbPAAAoIJxNQ4WyZkdv9rC83oPP7tWmPd1Drm1t79Ebv3a3Xv+fd2nn\n/r7i9d8/tUvZfKDXnHyEPvKq5Xpy+37d/Nj2w9KOuDr7BvSdu59RbzY/oe8LAEAchLNpaG5TjWY1\nVOvO6GD08bi7tuzt0c8ffk7faNug/tzQQLNzf58u+e97dcFXfqdv3/WMgsC1aU+33v5f96q9J6tc\nPtB3/vBs8fm/eXKnWuqr9OIlM/XGUxdq+bxG/dttTymXDw53N8f0hf9dq8/+8gl9++5nYn9NR09W\nd6/fnWCrAAAIsc/ZNFSVTuntZy7Sf925Qds6erWgpW7U59386Hb9fVuvOm69o3itsTYz5GD2a+/b\nrFzgOueoWfqnm57QLY8/r817etSfy+u696/UN9o26Pv3btJfrTpa9dUZ/XbtDr3iuHnKpMP/F3z0\ngmP1we8/pDd87W411WSUTpne+uIj9ZYXHzlm+7O5QDc9sk21VWktnd2gpXPqVV8d71f54c3tuu7+\nzarJpHT1Xc/ofectjfW1n/jJI7r18R367p+fpZcdOzfWewEAcDAYOZum3nnWYrmk6+7fPOrj63d2\n6aM3rNGMGtM/v+lk3fw3L9UZi1v0zbYNGohGubK5QD+4f7NWHTtX1/7F2frSW07RE9v2KxcEuu7y\nlTp54Qx94OVHqbMvp+vu36yHNrervWdArzyhtfg+F550hD748qM1p7Fa6ZRp+75effKnj2j9zq4x\n2/7pGx/X396wRn917UN67X/8Xid/+lZde9+msn3OB65/+PljmtdUo6ves0J7u7P6wX2j97/UUzs6\ndevj4SKGT/30UXX1H/pcvTzz7BK3ZW9P8XcVAF5ICGfT1KJZ9Tr/uHm67v4tyuaG/gPWN5DXh37w\nkOqq0/rIGTV698olOnFBsz70imP0XEevfv7wc5Kk/31su3Z19uvSc5fKzHTxmYvU9rFVuuUjL9Px\nR4RHUZ1yZIvOPXq2rr7rGd386HZVpU0vO3ZO8b3MTJ98zfH63mVn67rLV+pHHzxXdVVpffrGx0bd\nZuMH923Wdfdv1gdefpR+9Tcv0dffeYbOXDpLn7vpST3X0Ttun79/7yY9vm2//vH1J+rlx87VuUfP\n1lW/26i+gfHnnl15x3rVV6f13+95sbbt69UXbn4y1vd4NLl8oH/65RM67bO/1gPPTr193rbs7amI\nBR53PrVLL/+XO/SB762e0JI5ABwOFRXOzOzVZrbOzNab2Scnuz1T3btXLtHurn7d+vjzQ65//uYn\ntfb5Tn35badqZu3gr8j5x83TifObdWXbBuUD1//84Vktm9Ogly0fLPPNaazRnMaaIa/3gZcfrR37\n+/XdezZp5VGz1RQtSBjN3KYafezC43T3+j365SNDFwqs3rRXn77xMa06bq4+fuHxOmnBDL3ulPn6\n8sWnSpI+/YvHR33NfOB6dOs+/euv1+mly+fodS+aL0n60CuO0c7Ofv3owS1jtmdnT6Ab12zTu85e\nrFcc36rLzluma+/brD8cxPyz9u6sLv3O/fr23c/ITPrL768uGyhfSL555wa99Et36G+uf3hSA9H6\nnZ360LUPaU5jjX67dqc+fePj7KcXQ99AfsTqarww7O8b0Duuukcf+N6DZf+ziReGiglnZpaW9HVJ\nr5F0oqRLzOzEyW3V1PayY+dq0aw6ff/esCQYBK7r79+s796zSe9/6TKdf/y8Ic83M33oFcfomd3d\n+uIta/Xw5g6955wlSqVs/PdZPkfHH9GkfOD6kxNbx32uJL3z7CV60cIZ+txNT6izb0C5fKB7NuzR\nB7//kBa01Omrbz9d6ZL3PHJmvT7yquX6zZM7ikEzlw903f2b9a5v3atTP/trveFrd2kgH+izbzxJ\nZuHXnnPUbL14yUx9886NI0YPC27eOKBMOqX3v/QoSeE5qEtn1+sTP31ETx/AP2QPPrtXb/z6XXrg\nmXb9y1tP0U//6lz1DQS6/LsPvuBXjbq7vnjLWl3xv2t10oJm3fTIdn34+j9OSklxb3dWf/4/D6qm\nKq2f//V5+stVR+va+zbrm3dujPX1e7r6tXFXlx7duk8PPLtX/blkQ93z+/r0xy0dkx4e1+/s0hu/\ndpcu+Mrv9NlfPj7mn4fp7r6Ne3TxN+/RN0qmd0y2zr4BXfrt+/Xgs+269fEd+qtrHxqxcAsvPJW0\nIOAsSevdfaMkmdn1ki6S9MSktmoKS6dM7zp7ia7437X62m+f1s8efk4bdnXrjMUt+tiFx4/6Na8+\n6QgdM69RV/1uoxqq03rrOBP3C8xMH3nVsfq7H63RBSceEatd//ymk/WnV96tS/77Xj3X3qv2ngE1\n12b0/cvO1oz6kSNvf/6SZfrZw8/pMzc+rlze9ZXfPKX1O7t0bGuj3nT6Ap2xeKbOOXq25s8YXPxQ\nCJvv+84Det1//F4rj5qtM5fN0kkLmrVoZr32dmd113M5vePsxZrXHB4gX1ed1pcvPlWXfvsBXfjv\nv9ObTl+oD79yuXqyeT3w7F6t3tSulroqnblsls5aOkvrdnTq63es170b96q1uUY//MBKnb54piTp\nPy45TZdd86D+7kdr9I6zFmnH/n7t7OxTY01GC1vqtHBmnWozaXVnc+rJ5jWQD1SdTqk6E32kU6pK\np1STGbxmMv1xS4fuXr9bd2/YrT1dWWVSplTKNKu+Wi86coZOOXKGTlrQrPkz6tRQM/SvgCBw7e7u\n17aOPm3r6NVTO3Nq3b5fC1rq5O7asKtLG3Z2a093VjPqqjSzvkp3PrVL1z+wRe88e7H++aKTdfVd\nG/X5m9fK5froBcdpx74+bdvXp5pMSictaNbS2Q1lA/1YsrlAO/b3aW93Vr0DefUO5NWXzRc//+lD\nz+n5/X364eUrtaClTh+74Dg9196rL96yVnu6+nXWslk65cgWtTbXFEP6zs4+/XLNdv384ef06HP7\nhrxfbVq6qOMRXXzmkTphfrPcpcBde7qyWr+zS+t3den5fYNbxVRnUnrRwhk6a9kstUa/M/nAtbc7\nq/rqdPH7/VxHr668Y71+9OBWZfOBTlrQrA++/Gi95uQjiotlpDD4DuRd/bl88WdtZursG9Da5zv1\n5Pb92rSnR+3dWe3pzipw18uPnasLTzpCi2bVayAfaO32Tj2+bZ+a66p0zLxGLZ3doOrM4HvcuGab\nPvWTR1RTldafnr5Q37n7Wa3e1K4/O2rs8DGQD9STzas3m1cmHf5uxfmZurt6smFfSttQ6br7c/rS\nLWt1zT2b1FSb0f3P7tWNa7bpije/SKcuajmo1yz8WautShe3Nxquqz+np3Z0auf+Ph09t1HL5jQM\n+f3o6s/pvd95QI9u3acr33WGdndl9fc/e1R/fe3DuvJdZ4z5Pc7mAj2xfb8e3dqhuU01OuXIFs2f\nUVv8M3Ew3F29A3l19uW0vzf8T+3Clrpxf859A3lVp1PF352OnqweeLZdDzy7V+mU6aXL52jFklnj\nvsa2jl7dvnan7n56txbOrNOrTz5CZyyeOeQ/8C9ENtn/Yysws7dKerW7/0V0/92Sznb3D431NStW\nrPAHH3ww0Xa1tbVp1apVib7HZNrbndXKL9yubC7QCfOb9cGXH6XXvWh+8S+A0fr/04e26m9vWKP3\nnLNE/3TRybHfKwj8gP5R/qdfPqGfPLRVrzh+ni44sVUvO3buiDBRavWmdr31m3+Qu3TUnAZ94jXH\n64ITW8f9C8fd9b17N+m2J3Zo9aZ29USjWCmTGmsy6urP6c6Pna9Fs+qHfN3e7qy+eecGXfOHZ9Vf\nMsrQ2lyj/b059ZaUFo5ortX7X3aULjlr0YiVoVe2rdeXblkX+3sSVzplOm1Ri46cWad84Arc9fy+\nPj2+bf+Q9jbVZDS7sVr9uUBd/WEIPJjFCn+56mh9/MLjit/rb/1+oz73q9Hn5jVUp7VoVr3MbMiI\nkbvkchUuucKfj0d39vcNaHfX+HvzVaVNX774NL3x1AXFa/25vP7PDx7Wb57coULXqtMpySSTlM0H\ncpdOXtis171ogebPqFVDTUYm6Zrb/6jVu7z4ezGapppM8fe6dyBfHHVa2FKngXygPd3Z4ve0uTaj\n+TPqtHF3uODlbSsW6cT5zfr23c9o465uzWqoVnU6pf5cXn0DgfpzeZX+OMyk2kx6yO9XXVVasxur\nNauhOipNhq+9bE6DtnX0Dvl5S+HvRktdlWoyKWXSKW3e26MXL5mpr73zdM2fUadbHnteH//xGvVk\nc5rbVKt0ypROmfoHAvVkw9/tgfzQ35GqtGleU62aasM/M139OfVm86qrTquhOqPaqpS6+nNq7x5Q\nNhpxaqhOq6W+WnXVaaVMMpnMwv80pSzsa8pMZiaTomvhYwN510A+UDYXKGWm2qqUaqrC1+nN5tWT\nzas/F6gqbarOpFWdNgUu5QJXELhyQRDdDxQE4W34MzJVp03VmZSy/b2a2dykqnRK2/f1amdnv957\n7lJ97MLj9LunduvTNz6mXZ39OmZeY7GdqWKbS/qh8Frhuru0o7NP2zv6it+LxpqM5s8Iv395D/+u\nbO/Jamv70GkPNZmUjpnXqLqqtCRpZ2e/nuvo1dffebpefXI4XeN7927SP/78MS2f16jZjdWDvzsK\nf0f7cnk9MezvASmcktLaPDglpaurS01NjSN+30sjQ+BSTzYMY519OeWG/d2RMmn+jDrNbaop/ifR\n3bW7K6tdnf3FxVWNNRnVVae1q7NfUvjnM3BXLnDVV6d1wvxmmcL/GHn0vu6urv6cNu4K99hcMKNW\nu7uyyuYDzWms1vJ5TcW/Twp/txSaV/q7VPqzeceZi/W6U8LvY1L/9pvZandfUfZ5FRTO3ibpwmHh\n7Cx3/z/Dnne5pMslqbW19cXXX399ou3q6upSY+PIX9Cp5NFdOZmZTpqdGhFkRut/PnDdumlA5y7I\nqKWmsv73e+eWAbmklyzMKHOA/3PKB67NnYG2dQXa0ePa2RNoQW1Obzxu7J9/e1+gu57LaVat6diZ\nac2pM+Vd2rw/0FPtgRqrpbPnZ1Q1RlvcXU+1h39JttSYWmpMvTnX7j7Xnl5X3qWatFSbDv8iybtr\nIJByxQ8vfj7grnwgLWxM6fhZadVXjXzPXODa1hVoa5eroy/Q3j5XZ9ZVnbbwfTJhG+bUmWbWmjq7\ne9VjtdrTG/49Mb/BtKAxpeZqU0/O1T0Q/uNzZNPI34PHdue1rz/QrNqUZtaa+vOuTfsDbdofaE+v\nq/CrVmjl8PuFa4X7tRnT7NqwXc3Vppq0qTqtYturU1JdxlSTGf173Z8Lf77P7g/U3hf2xyXVZaQV\nrRktaBzZh66uLmVqG7R6R077+r3456OhSlrQkNL8xpQaSr7Pueh3aN3eQM/sy6smHX4/Z9SE/d8b\n/Vzn1Jles6xKs+vC9wzc9fDOvB7akVc6JVWlpKqUqSrqVyZlCtzVn5f6866GKtPippQWN6c0s8aG\n/Lnd2RNo9Y681u3Nq7XedFRLWkubU+rNubZ1u7Z3BeoeCH+PBgLXgsaUXrusasifl109gX71dI/y\nqSoFHv7eVaXC73NN2lSTiW7T0kAgdfS52vtdvTlXXcZUlwl/Ltn8YJvrMqbGKlNjlZRzqTvr6hoI\nHyv8LMJ/REtuC58Xgnt0P22mTErKpMLnZPNSNh8+XmhXVSp8n8Kfj/Af4sGPdPEf5sFr8sLXuPqy\nOSmVUS6Q0inp9UdVaXeJFaIAAAr/SURBVPnMdPF71DPgumnjgHb0BCPb7VIQdaoQCgrXJWlGjWlO\nXUqzak0DgbS3L/wz0Zf3Ypvq0tLCppSObEyppda0vSvQ5s5A27tcOQ9DR8qkVy2p0unzhv6n7/db\nB3TXc4Orykv/lU+btLgppWNmprVsRkr7+10b9wV6Zl/4e1H8Xc7llM6M/p/h0j9htRmpPmOqrwp/\n7vUZU12VaSDv2t3r2tkbaH//4PfAJDVVh38mmqpN+UDqzbl6c9LcetNxUbvyLq3dm9eju/Pa3hUU\n/y4YDPFhX5bPTOm0uRnNbzD15aVHduW1ekdOHf1ebGvxa6OGD/95BR5+vHJxRuctDEcxk/q3//zz\nz3/BhbNzJH3G3S+M7n9Kktz9C2N9DSNnyaP/9J/+r5rsZkyK6dx3if7T/8kdOaukYY8HJC03s2Vm\nVi3pHZJunOQ2AQD+//buP/aquo7j+PM1EEWaIZCmQqGFmTh/IqGZU9ICY+CmlUWTJpubpdIPK4yt\n1lybpdN0oc6UMGNaohE6Uxn5Y2n4A+PHF5EkMUQtMJGcOpV498fn89Wzr/fyQ7z3nO89r8f23fec\nz/mcez7v+77fc9/3nHO/x8zaqjJfCIiIzZLOBe4G+gCzIqLx/0YwMzMz61CVKc4AIuJO4M6yx2Fm\nZmZWliqd1jQzMzOrPRdnZmZmZhXi4szMzMysQlycmZmZmVWIizMzMzOzCnFxZmZmZlYhLs7MzMzM\nKsTFmZmZmVmFuDgzMzMzqxAXZ2ZmZmYV4uLMzMzMrEJcnJmZmZlViIszMzMzswpxcWZmZmZWIS7O\nzMzMzCpEEVH2GN4zSRuAf7Z4M0OAF1u8jSpz/I7f8ddTnWMHx+/4WxP/RyPiQ9vq1KuLs3aQ9FhE\njCp7HGVx/I7f8dcz/jrHDo7f8Zcbv09rmpmZmVWIizMzMzOzCnFxtm3Xlj2Akjn+enP89VXn2MHx\nO/4S+ZozMzMzswrxkTMzMzOzCnFxthWSxklaJWm1pOllj6fVJA2TdK+klZJWSJqW2wdJWiDpqfx7\nz7LH2iqS+kj6m6Q78vz+kh7Osf9OUr+yx9gqkgZKmivpyfwaOKZmuf92ft13SbpJ0m6dnH9JsySt\nl9RVaGuYbyVX5n3hMklHljfy90eT+C/Jr/9lkv4gaWBh2YU5/lWSPl/OqN8/jeIvLLtAUkgakudr\nkf/cfl7O8QpJPy+0tzX/Ls6akNQHmAmMBw4GviLp4HJH1XKbge9GxCeBMcA3c8zTgYURMQJYmOc7\n1TRgZWH+Z8DlOfaNwNRSRtUeVwB3RcRBwGGk56EWuZe0H3A+MCoiDgH6AGfQ2fmfDYzr0dYs3+OB\nEfnnbODqNo2xlWbz7vgXAIdExKHA34ELAfJ+8AxgZF7nqvwe0ZvN5t3xI2kYcDKwttBci/xLOhGY\nBBwaESOBS3N72/Pv4qy50cDqiHg6It4EbiYlrWNFxAsR8XiefoX05rwfKe4bcrcbgFPLGWFrSRoK\nfAG4Ls8LGAvMzV06OfY9gOOB6wEi4s2IeJma5D7rC/SX1BfYHXiBDs5/RDwAvNSjuVm+JwG/iWQR\nMFDSPu0ZaWs0ij8i7omIzXl2ETA0T08Cbo6INyJiDbCa9B7RazXJP8DlwPeB4gXptcg/cA5wcUS8\nkfusz+1tz7+Ls+b2A54tzK/LbbUgaThwBPAwsHdEvACpgAP2Km9kLfUL0k5pS54fDLxc2Fl38mvg\nAGAD8Ot8Wvc6SQOoSe4j4jnSp+S1pKJsE7CY+uS/W7N813F/eBbwpzxdi/glTQSei4ilPRbVIn7g\nQOAz+VKG+yUdndvbHr+Ls+bUoK0WX22V9AHgVuBbEfHfssfTDpImAOsjYnGxuUHXTn0N9AWOBK6O\niCOAV+nQU5iN5GurJgH7A/sCA0incnrq1PxvS53+FpA0g3SZx5zupgbdOip+SbsDM4AfNVrcoK2j\n4s/6AnuSLuv5HvD7fAal7fG7OGtuHTCsMD8UeL6ksbSNpF1IhdmciLgtN/+7+xB2/r2+2fq92KeB\niZKeIZ3CHks6kjYwn+aCzn4NrAPWRcTDeX4uqVirQ+4BTgLWRMSGiHgLuA04lvrkv1uzfNdmfyhp\nCjABmBzv/K+pOsT/MdKHk6V5PzgUeFzSh6lH/JDivC2fvn2EdBZlCCXE7+KsuUeBEfnbWv1IFwPO\nL3lMLZU/IVwPrIyIywqL5gNT8vQU4I/tHlurRcSFETE0IoaTcv3niJgM3Aucnrt1ZOwAEfEv4FlJ\nn8hNnwWeoAa5z9YCYyTtnv8OuuOvRf4LmuV7PnBm/tbeGGBT9+nPTiJpHPADYGJEvFZYNB84Q9Ku\nkvYnXRj/SBljbJWIWB4Re0XE8LwfXAccmfcNtcg/MI/0wRxJBwL9SDc/b3/+I8I/TX6AU0jf2PkH\nMKPs8bQh3uNIh2qXAUvyzymka68WAk/l34PKHmuLn4cTgDvy9AH5j3A1cAuwa9nja2HchwOP5fzP\nIx3er03ugZ8ATwJdwI3Arp2cf+Am0vV1b5HeiKc2yzfptM7MvC9cTvpWa+kxtCD+1aRri7r3f9cU\n+s/I8a8Cxpc9/lbE32P5M8CQmuW/H/DbvA94HBhbVv59hwAzMzOzCvFpTTMzM7MKcXFmZmZmViEu\nzszMzMwqxMWZmZmZWYW4ODMzMzOrEBdnZlY6SRMlbfWOBJL2lTQ3T39d0i93cBs/3I4+syWdvq1+\nrSLpPkmjytq+mVWDizMzK11EzI+Ii7fR5/mI2JnCaZvFWW9WuJOBmfVyLs7MrGUkDZf0ZL6Repek\nOZJOkvSgpKckjc793j4Slo9eXSnpIUlPdx/Jyo/VVXj4YZLukrRK0o8L25wnabGkFZLOzm0XA/0l\nLZE0J7edKWmZpKWSbiw87vE9t90gppWSfpW3cY+k/nnZ20e+JA3Jt8Hpjm+epNslrZF0rqTv5JvM\nL5I0qLCJr+XtdxWenwGSZkl6NK8zqfC4t0i6HbhnZ3JlZtXh4szMWu3jwBXAocBBwFdJd6O4gOZH\ns/bJfSYAzY6ojQYmk+5s8MXC6cCzIuIoYBRwvqTBETEdeD0iDo+IyZJGkv7j99iIOAyYtoPbHgHM\njIiRwMvAaVt7ArJDSLGPBn4KvBbpJvN/Bc4s9BsQEccC3wBm5bYZpFuKHQ2cCFwiaUBedgwwJSLG\nbscYzKwXcHFmZq22JtJ9+7YAK4CFkW5NshwY3mSdeRGxJSKeAPZu0mdBRPwnIl4n3aj8uNx+vqSl\nwCLSzYpHNFh3LDA3Il4EiIiXdnDbayJiSZ5evJU4iu6NiFciYgOwCbg9t/d8Hm7KY3oA2EPSQOBz\nwHRJS4D7gN2Aj+T+C3qM38x6OV+jYGat9kZhekthfgvN90HFddSkT897z4WkE4CTgGMi4jVJ95EK\nmZ7UYP0d2Xaxz/+A/nl6M+986O253e19Ht4VVx7HaRGxqrhA0qeAV5uM0cx6KR85M7Pe6mRJg/L1\nXqcCDwIfBDbmwuwgYEyh/1uSdsnTC4EvSRoM0OOar53xDHBUnn6vX174MoCk44BNEbEJuBs4T5Ly\nsiN2cpxmVmEuzsyst/oLcCOwBLg1Ih4D7gL6SloGXEQ6tdntWmCZpDkRsYJ03df9+RToZe/TmC4F\nzpH0EDDkPT7Gxrz+NcDU3HYRsAtp/F153sw6lNKlH2ZmZmZWBT5yZmZmZlYhLs7MzMzMKsTFmZmZ\nmVmFuDgzMzMzqxAXZ2ZmZmYV4uLMzMzMrEJcnJmZmZlViIszMzMzswr5P69dQB5d20qUAAAAAElF\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x100a9c5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n",
      "[0 1 0 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 1 1 0 1]\n",
      "[0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 0 1]\n",
      "true positive rate 0.9 true negative rate 0.975\n",
      "Test\n",
      "[0 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 0 1 0 1 0 1 0 1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 0 1 0 0 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0\n",
      " 0 1 0 0 0 1 0 1 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 0 0 1 0 1 0 1 0 1 0 0 0 1 0 1]\n",
      "[0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1]\n",
      "true positive rate 0.85 true negative rate 0.99\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print('Training')\n",
    "run_model_TF(sess,y_out,mean_loss,X_train,Y_train,10,64,100,train_step,True)\n",
    "\n",
    "mypredictions=tf.argmax(y_out,1)\n",
    "print('Validation')\n",
    "predicted_val=mypredictions.eval(feed_dict={X:X_val,is_training:True}, session=sess)\n",
    "print(predicted_val)\n",
    "print(Y_val)\n",
    "tpr_val,tnr_val=getTPTNRate(Y_val,predicted_val)\n",
    "print(\"true positive rate\",tpr_val,\"true negative rate\",tnr_val)\n",
    "\n",
    "print('Test')\n",
    "predicted_test=mypredictions.eval(feed_dict={X:X_test,is_training:True}, session=sess)\n",
    "print(predicted_test)\n",
    "print(Y_test)\n",
    "tpr_test,tnr_test=getTPTNRate(Y_test,predicted_test)\n",
    "print(\"true positive rate\",tpr_test,\"true negative rate\",tnr_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "validation:true positive rate 0.9 true negative rate 0.975\n",
    "\n",
    "test:true positive rate 0.85 true negative rate 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
