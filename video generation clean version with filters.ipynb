{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# automatically reload imported modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 227, 227) (400,)\n"
     ]
    }
   ],
   "source": [
    "import helper.get_image\n",
    "import numpy as np\n",
    "\n",
    "FOLDER_PATH = 'F://term7//CV//ProjectTrail//A_manualLabel'\n",
    "\n",
    "\n",
    "# random\n",
    "train_size = 200\n",
    "test_size = 100\n",
    "val_size = 40\n",
    "\n",
    "img_range = np.arange(1, 800)\n",
    "X_train_pos_idx, X_test_pos_idx, X_val_pos_idx = helper.get_random_indices(img_range, train_size, test_size, val_size)\n",
    "X_train_neg_idx, X_test_neg_idx, X_val_neg_idx = helper.get_random_indices(img_range, train_size, test_size, val_size)\n",
    "\n",
    "X_train, Y_train = helper.get_concrete_data(X_train_pos_idx, X_train_neg_idx, path = FOLDER_PATH)\n",
    "#X_test , Y_test  = helper.get_concrete_data(X_test_pos_idx, X_test_neg_idx, path = FOLDER_PATH)\n",
    "#X_val  , Y_val   = helper.get_concrete_data(X_val_pos_idx, X_val_neg_idx, path = FOLDER_PATH)\n",
    "\n",
    "print( X_train.shape, Y_train.shape )\n",
    "#print( X_test.shape , Y_test.shape  )\n",
    "#print( X_val.shape  , Y_val.shape   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from filters import *\n",
    "bilateral_canny = BilateralCanny()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filters = {}\n",
    "filters['canny']           = bilateral_canny.canny_img\n",
    "filters['bilateral canny'] = bilateral_canny.bilateral_canny_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from preprocessing import shadow_reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.array(list(shadow_reduction.adaptiveThreshold(x) for x in X_train))\n",
    "tmpX = np.array(list(filters['bilateral canny'](x) for x in X_train)).reshape(2*train_size, -1)\n",
    "model =  linear_model.LogisticRegression(C=1e5)\n",
    "model.fit(tmpX, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## video generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### video to frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "video_file = \"F://term7//CV//ProjectTrail//videos//IMG_5175.mov\"\n",
    "frame_folder = \"F://term7//CV//ProjectTrail//IMG_5175frame\"\n",
    "output_frame_folder =  \"F:\\\\term7\\\\CV\\\\ProjectTrail\\OutputIMG_5175\\\\\"\n",
    "output_video = \"F://term7//CV//ProjectTrail//videos//OutIMG_5175.mov\"\n",
    "\n",
    "from video import video\n",
    "v = video(video_file)\n",
    "# v.video_to_frames(frame_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process to video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " %reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'binary_dilation', 'ceil', 'count', 'cv2', 'dir', 'floor', 'generate_shadowed_img', 'generate_sub_frames', 'get_concrete_data', 'get_image', 'get_images', 'get_random_indices', 'get_stride', 'glob', 'ndimage', 'np', 'os', 'pattern', 'rename', 'rolling_window', 'save_image', 'shade_area', 'sys', 'titlePattern', 'utils']\n"
     ]
    }
   ],
   "source": [
    "import helper.utils\n",
    "import helper\n",
    "print(dir(helper))\n",
    "from helper import rolling_window, shade_area, utils, generate_shadowed_img\n",
    "import preprocessing.shadow_reduction\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CAREFUL!\n",
    "in the cell below:         frame_final = generate_shadowed_img(frame, frame_after_canny, model)\n",
    "\n",
    "in the function generate_shadowed_img, model.predict(img) will be called. So for CNN check the predict function again!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-e87e2b583824>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;31m#             time_pre = time.time()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mframe_final\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_shadowed_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe_after_canny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;31m#         time_predict_and_shadow += time.time() - time_pre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;31m#         time_pre = time.time()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\term7\\CV\\project\\helper\\shade_area.py\u001b[0m in \u001b[0;36mgenerate_shadowed_img\u001b[1;34m(origin, cannyed, model, stride, window_size)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mnx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mny\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnx\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mny\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mboxed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshade_area\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mboxed\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\term7\\CV\\project\\helper\\shade_area.py\u001b[0m in \u001b[0;36mshade_area\u001b[1;34m(img, imgs, result, window_size, stride, thickness)\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mstructure\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthickness\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbinary_dilation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstructure\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mboxed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0mboxed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_format = 'jpg'\n",
    "\n",
    "bilateral_canny_video = filters['canny']\n",
    "\n",
    "import time\n",
    "time_start = time.time()\n",
    "time_pre = time.time()\n",
    "time_norm = 0\n",
    "time_canny =  0\n",
    "time_predict_and_shadow = 0\n",
    "time_save = 0\n",
    "\n",
    "count = 0\n",
    "frameid = 0\n",
    "timelog = False\n",
    "\n",
    "for f in os.listdir(frame_folder):\n",
    "    if f.endswith(input_format):\n",
    "        image_path = os.path.join(frame_folder, f)\n",
    "        frame = cv2.imread(image_path)\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # reduce shadow by dilate, median, or threshold\n",
    "\n",
    "        if timelog:\n",
    "            time_pre = time.time()\n",
    "# shadow reduction\n",
    "#         frame_shadow_reduced = norm_dilate_median(gray_frame)\n",
    "        frame_shadow_reduced = shadow_reduction.adaptiveThreshold(gray_frame)\n",
    "        if timelog:\n",
    "            time_norm += time.time() - time_pre\n",
    "            time_pre = time.time()\n",
    "        \n",
    "            \n",
    "#         # generate output after canny filter, or tophat\n",
    "        frame_after_canny = bilateral_canny_video(frame_shadow_reduced)\n",
    "#         if timelog:\n",
    "#             time_canny += time.time() - time_pre\n",
    "#             time_pre = time.time()    \n",
    "        \n",
    "#         frame_final = generate_shadowed_img(frame, frame_after_canny, model)\n",
    "#         time_predict_and_shadow += time.time() - time_pre\n",
    "#         time_pre = time.time()\n",
    "        \n",
    "        # save to folder\n",
    "        utils.save_image(cv2.cvtColor(frame_final, cv2.COLOR_RGB2BGR), output_frame_folder, f)\n",
    "        time_save= time.time() - time_pre\n",
    "        time_pre = time.time()    \n",
    "        \n",
    "if timelog:\n",
    "    print(\"total time for frames generation is {}\".format(time.time()-time_start))\n",
    "    print(\"time norm{}\".format(time_norm))\n",
    "    print(\"time_canny{}\".format(time_canny))\n",
    "    print(\"time_predict_and_shadow{}\".format(time_predict_and_shadow))\n",
    "    print(\"time_save{}\".format(time_save))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### output to video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "from video import video\n",
    "v = video(video_file)\n",
    "v.frames_to_video(output_video, input_loc=output_frame_folder, debug=True)\n",
    "print(\"total time video saving {}\".format(time.time()-time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
