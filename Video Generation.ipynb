{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import helper.utils\n",
    "import helper\n",
    "from helper import rolling_window, shade_area, utils, generate_shadowed_img\n",
    "import preprocessing.shadow_reduction\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "TRAIN_DATA = 'C:\\\\Users\\\\Dominic\\\\Desktop\\\\Academics\\\\Term 7\\\\Computer Vision\\\\dump\\\\Concrete Crack Images for Classification'\n",
    "\n",
    "IN_VIDEO = \"C:\\\\Users\\\\Dominic\\\\Desktop\\\\Academics\\\\Term 7\\\\Computer Vision\\\\dump\\\\cnn out\\\\File_003.mov\"\n",
    "IN_FRAMES = \"C:\\\\Users\\\\Dominic\\\\Desktop\\\\Academics\\\\Term 7\\\\Computer Vision\\\\dump\\\\test\" # \"F://term7//CV//ProjectTrail//IMG_5175frame\"\n",
    "\n",
    "OUT_FRAMES =  \"C:\\\\Users\\\\Dominic\\\\Desktop\\\\Academics\\\\Term 7\\\\Computer Vision\\\\dump\\\\out_test\\\\\"\n",
    "OUT_VIDEO = \"C:\\\\Users\\\\Dominic\\\\Desktop\\\\Academics\\\\Term 7\\\\Computer Vision\\\\dump\\\\test.mov\"\n",
    "\n",
    "# automatically reload imported modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_size = 200\n",
    "test_size = 100\n",
    "val_size = 40\n",
    "\n",
    "img_range = np.arange(1, 800)\n",
    "X_train_pos_idx, X_test_pos_idx, X_val_pos_idx = helper.get_random_indices(img_range, train_size, test_size, val_size)\n",
    "X_train_neg_idx, X_test_neg_idx, X_val_neg_idx = helper.get_random_indices(img_range, train_size, test_size, val_size)\n",
    "\n",
    "X_train, Y_train = helper.get_concrete_data(X_train_pos_idx, X_train_neg_idx, path = TRAIN_DATA)\n",
    "#X_test , Y_test  = helper.get_concrete_data(X_test_pos_idx, X_test_neg_idx, path = TRAIN_DATA)\n",
    "#X_val  , Y_val   = helper.get_concrete_data(X_val_pos_idx, X_val_neg_idx, path = TRAIN_DATA)\n",
    "\n",
    "print( X_train.shape, Y_train.shape )\n",
    "#print( X_test.shape , Y_test.shape  )\n",
    "#print( X_val.shape  , Y_val.shape   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from filters import *\n",
    "from preprocessing import shadow_reduction\n",
    "bilateral_canny = BilateralCanny()\n",
    "\n",
    "filters = {}\n",
    "filters['canny']           = bilateral_canny.canny_img\n",
    "filters['bilateral canny'] = bilateral_canny.bilateral_canny_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "X_train = np.array(list(shadow_reduction.adaptiveThreshold(x) for x in X_train))\n",
    "tmpX = np.array(list(filters['bilateral canny'](x) for x in X_train)).reshape(2*train_size, -1)\n",
    "model =  linear_model.LogisticRegression(C=1e5)\n",
    "model.fit(tmpX, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video to Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from video import video\n",
    "v = video(IN_VIDEO)\n",
    "v.video_to_frames(IN_FRAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process to video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CAREFUL!\n",
    "in the cell below:         frame_final = generate_shadowed_img(frame, frame_after_canny, model)\n",
    "\n",
    "in the function generate_shadowed_img, model.predict(img) will be called. So for CNN check the predict function again!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_format = 'jpg'\n",
    "\n",
    "bilateral_canny_video = filters['canny']\n",
    "\n",
    "time_start = time.time()\n",
    "time_pre = time.time()\n",
    "time_norm = 0\n",
    "time_canny =  0\n",
    "time_predict_and_shadow = 0\n",
    "time_save = 0\n",
    "\n",
    "count = 0\n",
    "frameid = 0\n",
    "timelog = True\n",
    "\n",
    "for f in os.listdir(IN_FRAMES):\n",
    "    if f.endswith(input_format):\n",
    "        image_path = os.path.join(IN_FRAMES, f)\n",
    "        frame = cv2.imread(image_path)\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        if timelog:\n",
    "            time_pre = time.time()\n",
    "        \n",
    "        # shadow reduction\n",
    "        frame_shadow_reduced = shadow_reduction.adaptiveThreshold(gray_frame)\n",
    "        \n",
    "        if timelog:\n",
    "            time_norm += time.time() - time_pre\n",
    "            time_pre = time.time()\n",
    "        \n",
    "            \n",
    "        # generate output after canny filter, or tophat\n",
    "        frame_after_canny = bilateral_canny_video(frame_shadow_reduced)\n",
    "        \n",
    "        if timelog:\n",
    "            time_canny += time.time() - time_pre\n",
    "            time_pre = time.time()    \n",
    "        \n",
    "        # shadowed image\n",
    "        frame_final = generate_shadowed_img(frame, frame_after_canny, model)\n",
    "        \n",
    "        if timelog:\n",
    "            time_predict_and_shadow += time.time() - time_pre\n",
    "            time_pre = time.time()\n",
    "        \n",
    "        # save to folder\n",
    "        utils.save_image(cv2.cvtColor(frame_final, cv2.COLOR_RGB2BGR), OUT_FRAMES, f)\n",
    "        if timelog:\n",
    "            time_save = time.time() - time_pre\n",
    "            time_pre  = time.time()    \n",
    "        \n",
    "if timelog:\n",
    "    print(\"total time for frames generation is {}\".format(time.time()-time_start))\n",
    "    print(\"time norm               : {}\".format(time_norm))\n",
    "    print(\"time_canny              : {}\".format(time_canny))\n",
    "    print(\"time_predict_and_shadow : {}\".format(time_predict_and_shadow))\n",
    "    print(\"time_save               : {}\".format(time_save))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### output to video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "from video import video\n",
    "v = video(IN_VIDEO)\n",
    "v.frames_to_video(OUT_VIDEO, input_loc=OUT_FRAMES, debug=True)\n",
    "print(\"total time video saving {}\".format(time.time()-time_start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
