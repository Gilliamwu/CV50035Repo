{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# automatically reload imported modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import pylab as pl\n",
    "\n",
    "from filters import GrayscaleNormalizer\n",
    "\n",
    "# This is a bit of magic to make matplotlib figures appear inline in the notebook\n",
    "# rather than in a new window.\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "FOLDER_PATH = '/Users/delinwang/Desktop/Concrete Crack Images for Classification.rar Folder/'\n",
    "FOLDER_PATH = 'C:/Users/Dominic/Desktop/Concrete Crack Images for Classification/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 227, 227) (400,)\n",
      "(200, 227, 227) (200,)\n",
      "(100, 227, 227) (100,)\n"
     ]
    }
   ],
   "source": [
    "import helper\n",
    "\n",
    "FOLDER_PATH = 'F://term7//CV//reference'\n",
    "#FOLDER_PATH = 'F://term7//CV//ProjectTrail//A_manualLabel'\n",
    "#FOLDER_PATH = 'C://Users//Dominic//Desktop//Concrete Crack Images for Classification'\n",
    "\n",
    "# random\n",
    "train_size = 200\n",
    "test_size = 100\n",
    "val_size = 50\n",
    "\n",
    "img_range = np.arange(1, 800)\n",
    "X_train_pos_idx, X_test_pos_idx, X_val_pos_idx = helper.get_random_indices(img_range, train_size, test_size, val_size)\n",
    "X_train_neg_idx, X_test_neg_idx, X_val_neg_idx = helper.get_random_indices(img_range, train_size, test_size, val_size)\n",
    "\n",
    "X_train, Y_train = helper.get_concrete_data(X_train_pos_idx, X_train_neg_idx, path = FOLDER_PATH)\n",
    "X_test , Y_test  = helper.get_concrete_data(X_test_pos_idx, X_test_neg_idx, path = FOLDER_PATH)\n",
    "X_val  , Y_val   = helper.get_concrete_data(X_val_pos_idx, X_val_neg_idx, path = FOLDER_PATH)\n",
    "\n",
    "print( X_train.shape, Y_train.shape )\n",
    "print( X_test.shape , Y_test.shape  )\n",
    "print( X_val.shape  , Y_val.shape   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from filters import *\n",
    "import preprocessing.shadow_reduction\n",
    "\n",
    "filters = {}\n",
    "\n",
    "grayscale       = GrayscaleNormalizer()\n",
    "bilateral_canny = BilateralCanny()\n",
    "\n",
    "filters['no filter'] = lambda x : x\n",
    "filters['grayscale']       = grayscale.__call__\n",
    "filters['canny']           = bilateral_canny.canny_img\n",
    "filters['bilateral canny'] = bilateral_canny.bilateral_canny_img\n",
    "filters['tophat']          = tophat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import linear_model\n",
    "\n",
    "def get_models():\n",
    "    models = {}\n",
    "    \n",
    "    models['clf']      = svm.SVC()\n",
    "    models['neigh']    = KNeighborsClassifier(n_neighbors=3)\n",
    "    models['regr']     = linear_model.LinearRegression()\n",
    "    models['logistic'] = linear_model.LogisticRegression(C=1e5)\n",
    "    \n",
    "    return models\n",
    "\n",
    "trained_models = {}\n",
    "\n",
    "X_train = np.array(list(shadow_reduction.adaptiveThreshold(x) for x in X_train))\n",
    "\n",
    "for filter_name, filter_func in filters.items():\n",
    "    tmpX = np.array(list(filter_func(x) for x in X_train)).reshape(2*train_size, -1)\n",
    "    \n",
    "    sub_dict = {}\n",
    "    \n",
    "    for model_name, model in get_models().items():\n",
    "        model.fit(tmpX, Y_train)\n",
    "        \n",
    "        sub_dict[model_name] = model\n",
    "        \n",
    "    trained_models[filter_name] = sub_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict   = {}\n",
    "\n",
    "for filter_name, filter_func in filters.items():\n",
    "    tmpX = np.array(list(filter_func(x) for x in X_test)).reshape(2*test_size, -1)\n",
    "    \n",
    "    for model_name, model in trained_models[filter_name].items():\n",
    "        result = model.predict(tmpX)\n",
    "\n",
    "        predict[\"{0}, {1}\".format(filter_name, model_name)] = (result[:test_size], result[test_size:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grayscale, clf\n",
      "  100.00 / 100.00  \n",
      "    4.00 / 100.00  \n",
      "grayscale, neigh\n",
      "   24.00 / 100.00  \n",
      "  100.00 / 100.00  \n",
      "grayscale, regr\n",
      "   63.00 / 100.00  \n",
      "  100.00 / 100.00  \n",
      "grayscale, logistic\n",
      "   69.00 / 100.00  \n",
      "   99.00 / 100.00  \n",
      "canny, clf\n",
      "  100.00 / 100.00  \n",
      "   27.00 / 100.00  \n",
      "canny, neigh\n",
      "    0.00 / 100.00  \n",
      "  100.00 / 100.00  \n",
      "canny, regr\n",
      "   85.00 / 100.00  \n",
      "   93.00 / 100.00  \n",
      "canny, logistic\n",
      "   81.00 / 100.00  \n",
      "   89.00 / 100.00  \n",
      "bilateral canny, clf\n",
      "  100.00 / 100.00  \n",
      "   42.00 / 100.00  \n",
      "bilateral canny, neigh\n",
      "    0.00 / 100.00  \n",
      "  100.00 / 100.00  \n",
      "bilateral canny, regr\n",
      "   88.00 / 100.00  \n",
      "   98.00 / 100.00  \n",
      "bilateral canny, logistic\n",
      "   88.00 / 100.00  \n",
      "   94.00 / 100.00  \n",
      "tophat, clf\n",
      "  100.00 / 100.00  \n",
      "   48.00 / 100.00  \n",
      "tophat, neigh\n",
      "    0.00 / 100.00  \n",
      "  100.00 / 100.00  \n",
      "tophat, regr\n",
      "   87.00 / 100.00  \n",
      "   89.00 / 100.00  \n",
      "tophat, logistic\n",
      "   62.00 / 100.00  \n",
      "   98.00 / 100.00  \n"
     ]
    }
   ],
   "source": [
    "for name, model in predict.items():\n",
    "    print(name)\n",
    "    \n",
    "    if 'regr' in name:\n",
    "        pos_count = 0\n",
    "        neg_count = 0\n",
    "        \n",
    "        for i in predict[name][0]:\n",
    "            if i > 0.5:\n",
    "                pos_count +=1\n",
    "        for i in predict[name][1]:\n",
    "            if i > 0.5:\n",
    "                neg_count +=1\n",
    "                \n",
    "    else:\n",
    "        pos_count   = np.sum(predict[name][0])\n",
    "        neg_count   = np.sum(predict[name][1])\n",
    "        \n",
    "    print(\"{0:>8.2f} / {1:<8.2f}\".format(pos_count, test_size))\n",
    "    print(\"{0:>8.2f} / {1:<8.2f}\".format(test_size - neg_count, test_size))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
