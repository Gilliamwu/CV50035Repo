{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import *\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "landmarks = [[20.0, 20.0], [80.0, 80.0], [20.0, 80.0], [80.0, 20.0]]\n",
    "world_size = 100.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Robot:\n",
    "    \"\"\"\n",
    "    This class aims for describing a robot.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.x = random.random() * world_size\n",
    "        self.y = random.random() * world_size\n",
    "        self.orientation = random.random() * 2.0 * pi\n",
    "        self.forward_noise = 0.0\n",
    "        self.turn_noise = 0.0\n",
    "        self.sense_noise = 0.0\n",
    "\n",
    "    def set(self, new_x, new_y, new_orientation):\n",
    "        \"\"\"\n",
    "        This function aims to set the 2d pose of the robot.\n",
    "        :param new_x: The x coordinate of the robot.\n",
    "        :param new_y: The y coordinate of the robot.\n",
    "        :param new_orientation: The orientation of the robot.\n",
    "        :return: None.\n",
    "        \"\"\"\n",
    "        if new_x < 0 or new_x >= world_size:\n",
    "            raise (ValueError, 'X coordinate out of bound')\n",
    "        if new_y < 0 or new_y >= world_size:\n",
    "            raise (ValueError, 'Y coordinate out of bound')\n",
    "        if new_orientation < 0 or new_orientation >= 2 * pi:\n",
    "            raise (ValueError, 'Orientation must be in [0..2pi]')\n",
    "        self.x = float(new_x)\n",
    "        self.y = float(new_y)\n",
    "        self.orientation = float(new_orientation)\n",
    "\n",
    "    def set_noise(self, new_f_noise, new_t_noise, new_s_noise):\n",
    "        \"\"\"\n",
    "        This function makes it possible to change the noise parameters and\n",
    "        it is often useful in particle filters.\n",
    "        :param new_f_noise: The forward noise.\n",
    "        :param new_t_noise: The turn noise.\n",
    "        :param new_s_noise: The observation noise.\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        self.forward_noise = float(new_f_noise)\n",
    "        self.turn_noise = float(new_t_noise)\n",
    "        self.sense_noise = float(new_s_noise)\n",
    "\n",
    "    def sense(self):\n",
    "        \"\"\"\n",
    "        This function aims to get the observation of the robot.\n",
    "        :return: A list of the observation. The size depend on the landmarks.\n",
    "        \"\"\"\n",
    "        Z = []\n",
    "        for i in range(len(landmarks)):\n",
    "            dist = sqrt((self.x - landmarks[i][0]) ** 2 + (self.y - landmarks[i][1]) ** 2)\n",
    "            dist += random.gauss(0.0, self.sense_noise)\n",
    "            Z.append(dist)\n",
    "        return Z\n",
    "\n",
    "    def move(self, turn, forward):\n",
    "        \"\"\"\n",
    "        This function realize the movement of the robot.\n",
    "        :param turn: The orientation of the robot.\n",
    "        :param forward: The length of the robot need to move.\n",
    "        :return: The robot which is moved according to the input params.\n",
    "        \"\"\"\n",
    "        if forward < 0:\n",
    "            raise (ValueError, 'Robot cant move backwards')\n",
    "        # turn, and add randomness to the turning command\n",
    "        orientation = self.orientation + float(turn) + random.gauss(0.0, self.turn_noise)\n",
    "        orientation %= 2 * pi\n",
    "\n",
    "        # move, and add randomness to the motion command\n",
    "        dist = float(forward) + random.gauss(0.0, self.forward_noise)\n",
    "        x = self.x + (cos(orientation) * dist)\n",
    "        y = self.y + (sin(orientation) * dist)\n",
    "        x %= world_size  # cyclic truncate\n",
    "        y %= world_size\n",
    "\n",
    "        # set particle\n",
    "        res = Robot()\n",
    "        res.set(x, y, orientation)\n",
    "        res.set_noise(self.forward_noise, self.turn_noise, self.sense_noise)\n",
    "        return res\n",
    "\n",
    "    def gaussian(self, mu, sigma, x):\n",
    "        \"\"\"\n",
    "        This function aims to calculates the probability of x for 1-dim Gaussian with mean mu and var. sigma\n",
    "        :param mu: The mean of the gaussian distribution.\n",
    "        :param sigma: The variance of the gaussian distribution.\n",
    "        :param x: The input value.\n",
    "        :return: The probability of the input x.\n",
    "        \"\"\"\n",
    "        return exp(- ((mu - x) ** 2) / (sigma ** 2) / 2.0) / sqrt(2.0 * pi * (sigma ** 2))\n",
    "\n",
    "    def measurement_prob(self, measurement):\n",
    "        \"\"\"\n",
    "        This function aims to calculates how likely a measurement should be.\n",
    "        :param measurement: The observation of the robot or particle.\n",
    "        :return: The probability of the measurement.\n",
    "        \"\"\"\n",
    "        prob = 1.0\n",
    "        for i in range(len(landmarks)):\n",
    "            dist = sqrt((self.x - landmarks[i][0]) ** 2 + (self.y - landmarks[i][1]) ** 2)\n",
    "            prob *= self.gaussian(dist, self.sense_noise, measurement[i])\n",
    "        return prob\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        This function aims to overload the print.\n",
    "        :return: The position of the robot.\n",
    "        \"\"\"\n",
    "        return '[x=%.6s y=%.6s orient=%.6s]' % (str(self.x), str(self.y), str(self.orientation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_map' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-b29c7fa27527>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Step1: Show the map.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmap_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnamedWindow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'map_image'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'map_image'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'create_map' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step1: Show the map.\n",
    "map_image = create_map()\n",
    "cv2.namedWindow('map_image')\n",
    "cv2.imshow('map_image', map_image)\n",
    "# Create the robot.\n",
    "myrobot = Robot()\n",
    "# Show the robot pose in the map.\n",
    "map_image = show_robot_pose(myrobot, map_image)\n",
    "cv2.imshow('map_image', map_image)\n",
    "cv2.waitKey(0)\n",
    "# Generate particles.\n",
    "N = 1000\n",
    "p = []\n",
    "for i in range(N):\n",
    "    x = Robot()\n",
    "    x.set_noise(0.05, 0.05, 5)\n",
    "    p.append(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afterwards\n",
    "crack like pixels were detected by applying two thresholds\n",
    "as the first threshold detected the dark pixels and on the\n",
    "basis of next threshold a pixel was labeled crack-like\n",
    "when not only its grey level lied within the two thresholds\n",
    "but also if it was spatially connected to a crack-like pixel,\n",
    "previously detected by first threshold. Next to keep the\n",
    "(continuous) crack pixels and to diminish the isolated ones\n",
    "“opening” and “closing” operation was applied.\n",
    "Finally the pixels were projected into four axes to\n",
    "determine any high peak corresponding to the crack pixels\n",
    "while the projection results in different direction did not\n",
    "show any high peak. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outcome of density and histogram features extraction from\n",
    "the input image to a neural network classifier which\n",
    "categorized the result as defective and non defective\n",
    "images. Afterwards another classifier identified the type of\n",
    "crack in the defective images. The method proposed in\n",
    "[12] divided the acquired images into a training set and a\n",
    "testing set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each image was preprocessed with intensity\n",
    "normalization followed by pixel saturation, feature\n",
    "extraction and feature normalization. Afterwards for\n",
    "system training hierarchical, k-means and Gaussian\n",
    "mixture model was considered. Crack detection results\n",
    "were acquired by using k-means. Final step comprised of\n",
    "labeling of crack types. T. Saar and O. Talvik [13] first\n",
    "equalized intensity values in the input image.\n",
    "Subsequently features were extracted to be supplied to the\n",
    "neural network for crack detection and classification. Four\n",
    "nodes of the network classified the crack as no crack,\n",
    "longitudinal, transverse and alligator crack. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wei Xu et al [14] dealt with noise in pavement images\n",
    "by considering the histogram based intensity, rare\n",
    "features, and the contrast features of pixels and developed\n",
    "a conspicuity map. To address dark textures, and shadows\n",
    "due to their high intensity rarity and contrast, spatial\n",
    "features were considered. A probabilistic algorithm\n",
    "namely Bayesian model was proposed which connected\n",
    "crack pixels up to a certain length. Finally a binarization\n",
    "of saliency map, by taking Otsu threshold, detected the\n",
    "whole crack. Road cracks were extracted by Sylvie\n",
    "Chambon et al [15] by first applying adaptive filtering in\n",
    "order to obtain a binary image followed by Markov model\n",
    "based segmentation. They also accorded an estimation and\n",
    "comparison protoco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
