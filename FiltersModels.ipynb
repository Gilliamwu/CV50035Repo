{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# automatically reload imported modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import pylab as pl\n",
    "\n",
    "# This is a bit of magic to make matplotlib figures appear inline in the notebook\n",
    "# rather than in a new window.\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 227, 227) (1200,)\n",
      "(400, 227, 227) (400,)\n",
      "(100, 227, 227) (100,)\n"
     ]
    }
   ],
   "source": [
    "import helper\n",
    "\n",
    "# FOLDER_PATH = 'F://term7//CV//reference'\n",
    "FOLDER_PATH = 'D:\\\\ISTD\\\\Computer Vision\\\\Project\\\\ref2'\n",
    "#FOLDER_PATH = 'F://term7//CV//ProjectTrail//A_manualLabel'\n",
    "# FOLDER_PATH = 'C://Users//Dominic//Desktop//Concrete Crack Images for Classification'\n",
    "\n",
    "# random\n",
    "train_size = 600\n",
    "test_size = 200\n",
    "val_size = 50\n",
    "\n",
    "img_range = np.arange(1, 1000)\n",
    "X_train_pos_idx, X_test_pos_idx, X_val_pos_idx = helper.get_random_indices(img_range, train_size, test_size, val_size)\n",
    "X_train_neg_idx, X_test_neg_idx, X_val_neg_idx = helper.get_random_indices(img_range, train_size, test_size, val_size)\n",
    "\n",
    "X_train , Y_train = helper.get_concrete_data( X_train_pos_idx , X_train_neg_idx , path = FOLDER_PATH )\n",
    "X_test  , Y_test  = helper.get_concrete_data( X_test_pos_idx  , X_test_neg_idx  , path = FOLDER_PATH )\n",
    "X_val   , Y_val   = helper.get_concrete_data( X_val_pos_idx   , X_val_neg_idx   , path = FOLDER_PATH )\n",
    "\n",
    "print( X_train.shape, Y_train.shape )\n",
    "print( X_test.shape , Y_test.shape  )\n",
    "print( X_val.shape  , Y_val.shape   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from filters import *\n",
    "import preprocessing.shadow_reduction\n",
    "\n",
    "filters = {}\n",
    "\n",
    "grayscale       = GrayscaleNormalizer()\n",
    "bilateral_canny = BilateralCanny()\n",
    "\n",
    "filters['no filter']       = lambda x : x\n",
    "filters['grayscale']       = grayscale.__call__\n",
    "filters['canny']           = bilateral_canny.canny_img\n",
    "filters['bilateral canny'] = bilateral_canny.bilateral_canny_img\n",
    "filters['tophat']          = tophat\n",
    "filters['canny gradient']  = canny_gradient\n",
    "filters['otsu']            = otsu\n",
    "filters['blackhat']        = blackhat\n",
    "filters['gradient']        = gradient\n",
    "filters['gradient2']       = gradient2\n",
    "filters['gradient3']       = gradient3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import linear_model\n",
    "\n",
    "def get_models():\n",
    "    models = {}\n",
    "    \n",
    "    models['clf']      = svm.SVC()\n",
    "    models['neigh']    = KNeighborsClassifier(n_neighbors=3)\n",
    "    models['regr']     = linear_model.LinearRegression()\n",
    "    models['logistic'] = linear_model.LogisticRegression(C=1e5)\n",
    "    \n",
    "    return models\n",
    "\n",
    "trained_models = {}\n",
    "\n",
    "X_train = np.array(list(preprocessing.shadow_reduction.adaptiveThreshold(x) for x in X_train))\n",
    "\n",
    "for filter_name, filter_func in filters.items():\n",
    "    tmpX = np.array(list(filter_func(x) for x in X_train)).reshape(2*train_size, -1)\n",
    "    \n",
    "    sub_dict = {}\n",
    "    \n",
    "    for model_name, model in get_models().items():\n",
    "        model.fit(tmpX, Y_train)\n",
    "        \n",
    "        sub_dict[model_name] = model\n",
    "        \n",
    "    trained_models[filter_name] = sub_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict   = {}\n",
    "\n",
    "for filter_name, filter_func in filters.items():\n",
    "    tmpX = np.array(list(filter_func(x) for x in X_test)).reshape(2*test_size, -1)\n",
    "    \n",
    "    for model_name, model in trained_models[filter_name].items():\n",
    "        result = model.predict(tmpX)\n",
    "\n",
    "        predict[\"{0}, {1}\".format(filter_name, model_name)] = (result[:test_size], result[test_size:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no filter, clf\n",
      "  200.00 / 200.00  \n",
      "    0.00 / 200.00  \n",
      "no filter, neigh\n",
      "    0.00 / 200.00  \n",
      "  200.00 / 200.00  \n",
      "no filter, regr\n",
      "  200.00 / 200.00  \n",
      "    0.00 / 200.00  \n",
      "no filter, logistic\n",
      "    1.00 / 200.00  \n",
      "  200.00 / 200.00  \n",
      "grayscale, clf\n",
      "  200.00 / 200.00  \n",
      "    2.00 / 200.00  \n",
      "grayscale, neigh\n",
      "    0.00 / 200.00  \n",
      "  200.00 / 200.00  \n",
      "grayscale, regr\n",
      "    4.00 / 200.00  \n",
      "  200.00 / 200.00  \n",
      "grayscale, logistic\n",
      "    3.00 / 200.00  \n",
      "  200.00 / 200.00  \n",
      "canny, clf\n",
      "  102.00 / 200.00  \n",
      "  157.00 / 200.00  \n",
      "canny, neigh\n",
      "    0.00 / 200.00  \n",
      "  200.00 / 200.00  \n",
      "canny, regr\n",
      "    0.00 / 200.00  \n",
      "  200.00 / 200.00  \n",
      "canny, logistic\n",
      "   55.00 / 200.00  \n",
      "  174.00 / 200.00  \n",
      "bilateral canny, clf\n",
      "   38.00 / 200.00  \n",
      "  184.00 / 200.00  \n",
      "bilateral canny, neigh\n",
      "    0.00 / 200.00  \n",
      "  200.00 / 200.00  \n",
      "bilateral canny, regr\n",
      "    0.00 / 200.00  \n",
      "  200.00 / 200.00  \n",
      "bilateral canny, logistic\n",
      "   18.00 / 200.00  \n",
      "  191.00 / 200.00  \n",
      "tophat, clf\n",
      "  117.00 / 200.00  \n",
      "   80.00 / 200.00  \n",
      "tophat, neigh\n",
      "    0.00 / 200.00  \n",
      "  200.00 / 200.00  \n",
      "tophat, regr\n",
      "    5.00 / 200.00  \n",
      "  199.00 / 200.00  \n",
      "tophat, logistic\n",
      "   48.00 / 200.00  \n",
      "  151.00 / 200.00  \n",
      "canny gradient, clf\n",
      "   38.00 / 200.00  \n",
      "  183.00 / 200.00  \n",
      "canny gradient, neigh\n",
      "   32.00 / 200.00  \n",
      "  188.00 / 200.00  \n",
      "canny gradient, regr\n",
      "   25.00 / 200.00  \n",
      "  189.00 / 200.00  \n",
      "canny gradient, logistic\n",
      "   26.00 / 200.00  \n",
      "  189.00 / 200.00  \n",
      "otsu, clf\n",
      "   87.00 / 200.00  \n",
      "   24.00 / 200.00  \n",
      "otsu, neigh\n",
      "   55.00 / 200.00  \n",
      "   95.00 / 200.00  \n",
      "otsu, regr\n",
      "  157.00 / 200.00  \n",
      "    4.00 / 200.00  \n",
      "otsu, logistic\n",
      "  146.00 / 200.00  \n",
      "   20.00 / 200.00  \n",
      "blackhat, clf\n",
      "   93.00 / 200.00  \n",
      "  113.00 / 200.00  \n",
      "blackhat, neigh\n",
      "    0.00 / 200.00  \n",
      "  200.00 / 200.00  \n",
      "blackhat, regr\n",
      "    0.00 / 200.00  \n",
      "  200.00 / 200.00  \n",
      "blackhat, logistic\n",
      "  128.00 / 200.00  \n",
      "   79.00 / 200.00  \n",
      "gradient, clf\n",
      "  200.00 / 200.00  \n",
      "    0.00 / 200.00  \n",
      "gradient, neigh\n",
      "    0.00 / 200.00  \n",
      "  200.00 / 200.00  \n",
      "gradient, regr\n",
      "    0.00 / 200.00  \n",
      "  200.00 / 200.00  \n",
      "gradient, logistic\n",
      "  111.00 / 200.00  \n",
      "  112.00 / 200.00  \n",
      "gradient2, clf\n",
      "  200.00 / 200.00  \n",
      "    0.00 / 200.00  \n",
      "gradient2, neigh\n",
      "    4.00 / 200.00  \n",
      "  189.00 / 200.00  \n",
      "gradient2, regr\n",
      "  197.00 / 200.00  \n",
      "   11.00 / 200.00  \n",
      "gradient2, logistic\n",
      "  178.00 / 200.00  \n",
      "   40.00 / 200.00  \n",
      "gradient3, clf\n",
      "  200.00 / 200.00  \n",
      "    0.00 / 200.00  \n",
      "gradient3, neigh\n",
      "    0.00 / 200.00  \n",
      "  197.00 / 200.00  \n",
      "gradient3, regr\n",
      "  170.00 / 200.00  \n",
      "   43.00 / 200.00  \n",
      "gradient3, logistic\n",
      "  131.00 / 200.00  \n",
      "   84.00 / 200.00  \n"
     ]
    }
   ],
   "source": [
    "for name, model in predict.items():\n",
    "    print(name)\n",
    "    \n",
    "    if 'regr' in name:\n",
    "        pos_count = 0\n",
    "        neg_count = 0\n",
    "        \n",
    "        for i in predict[name][0]:\n",
    "            if i > 0.5:\n",
    "                pos_count +=1\n",
    "        for i in predict[name][1]:\n",
    "            if i > 0.5:\n",
    "                neg_count +=1\n",
    "                \n",
    "    else:\n",
    "        pos_count   = np.sum(predict[name][0])\n",
    "        neg_count   = np.sum(predict[name][1])\n",
    "        \n",
    "    print(\"{0:>8.2f} / {1:<8.2f}\".format(pos_count, test_size))\n",
    "    print(\"{0:>8.2f} / {1:<8.2f}\".format(test_size - neg_count, test_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
